{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "449b2072",
   "metadata": {
    "id": "449b2072"
   },
   "source": [
    "# Lezione Completa: Costruzione di una Pipeline Dati per Video YouTube\n",
    "\n",
    "**Obiettivo del Notebook:** In questa sessione, costruiremo passo dopo passo una pipeline di dati completa per raccogliere, elaborare, validare e arricchire informazioni provenienti da video di YouTube. Impareremo a interagire con API esterne, gestire dati testuali, effettuare pulizia e trasformazioni, e infine generare *embedding* semantici dal testo. Questo notebook è pensato per essere una guida didattica completa per data scientist e data engineer.\n",
    "\n",
    "**Cosa imparerai:**\n",
    "* Comprendere la struttura di un progetto di data pipeline.\n",
    "* Interagire con l'API di YouTube Data v3 per recuperare metadati dei video.\n",
    "* Utilizzare `youtube_transcript_api` per scaricare le trascrizioni dei video.\n",
    "* Eseguire l'ispezione e la validazione dei dati raccolti per identificare problemi di qualità.\n",
    "* Effettuare operazioni di pulizia e pre-elaborazione su dati testuali (titoli e trascrizioni) basate sui risultati della validazione.\n",
    "* Convertire e standardizzare i tipi di dati utilizzando la libreria Polars.\n",
    "* Generare *embedding* testuali con `sentence-transformers` per catturare il significato semantico del testo.\n",
    "* Strutturare una pipeline di dati modulare e riutilizzabile in Python.\n",
    "* Salvare i dati elaborati in formati efficienti come Parquet.\n",
    "* Comprendere come automatizzare tale pipeline utilizzando GitHub Actions.\n",
    "\n",
    "Questo notebook è pensato per essere interattivo e auto-eseguibile. Sentiti libero di modificare il codice, sperimentare con i parametri e osservare i risultati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088f238",
   "metadata": {
    "id": "b088f238"
   },
   "source": [
    "## 0. Prerequisiti e Istruzioni per l'Esecuzione\n",
    "\n",
    "Prima di iniziare, assicurati di aver configurato correttamente il tuo ambiente.\n",
    "\n",
    "### 0.1. Ambiente Virtuale (Consigliato)\n",
    "Per mantenere le dipendenze del progetto isolate, è buona pratica utilizzare un ambiente virtuale (ad es. con `venv` o `conda`).\n",
    "```bash\n",
    "# Esempio con venv\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate  # Su macOS/Linux\n",
    "# .venv\\Scripts\\activate    # Su Windows (prompt dei comandi)\n",
    "# .venv\\Scripts\\Activate.ps1 # Su Windows (PowerShell)\n",
    "```\n",
    "\n",
    "### 0.2. Installazione delle Librerie Python\n",
    "Le seguenti librerie sono necessarie. Puoi installarle eseguendo il comando sottostante nel terminale del tuo ambiente virtuale, o direttamente in una cella di codice del notebook anteponendo `!pip install ...`. È consigliabile utilizzare un file `requirements.txt` per gestire le dipendenze in progetti reali.\n",
    "\n",
    "Un esempio di file `requirements.txt` potrebbe contenere:\n",
    "```\n",
    "requests\n",
    "polars\n",
    "youtube-transcript-api\n",
    "sentence-transformers\n",
    "pandas\n",
    "jupyterlab\n",
    "matplotlib\n",
    "accelerate\n",
    "```\n",
    "E poi installarle con:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "Oppure, per una installazione diretta:\n",
    "```bash\n",
    "pip install requests polars youtube-transcript-api sentence-transformers pandas jupyterlab matplotlib accelerate\n",
    "```\n",
    "\n",
    "### 0.3. Chiave API di YouTube\n",
    "Per recuperare i metadati dei video da YouTube (Passo 2.1 della pipeline), è **necessaria** una chiave API di YouTube Data v3.\n",
    "1.  Ottieni una chiave API dalla [Google Cloud Console](https://console.cloud.google.com/apis/credentials).\n",
    "2.  Nel tuo progetto Google Cloud, abilita l'API \"YouTube Data API v3\".\n",
    "3.  **Importante per la Sicurezza:** Imposta la tua chiave API come variabile d'ambiente chiamata `YT_API_KEY`. **Non inserire mai la chiave API direttamente nel codice o committarla in un repository Git.**\n",
    "    * **Linux/macOS (terminale):** `export YT_API_KEY='LA_TUA_CHIAVE_API'`\n",
    "    * **Windows (PowerShell):** `$env:YT_API_KEY='LA_TUA_CHIAVE_API'`\n",
    "    * **Windows (Prompt dei comandi):** `set YT_API_KEY=LA_TUA_CHIAVE_API`\n",
    "    *(Per rendere l'impostazione persistente, aggiungi questi comandi al file di configurazione della tua shell, come `.bashrc`, `.zshrc`, o usa strumenti come `python-dotenv` in un ambiente di sviluppo locale, assicurandoti che il file `.env` non sia tracciato da Git)*.\n",
    "\n",
    "    **Nota Importante:** Se la variabile d'ambiente `YT_API_KEY` non è configurata correttamente, la pipeline utilizzerà dati segnaposto per il recupero degli ID video, permettendo comunque di eseguire i passaggi successivi con dati fittizi. Questo è utile per testare il flusso della pipeline senza chiamate API reali.\n",
    "\n",
    "### 0.4. Esecuzione del Notebook\n",
    "1.  Salva questo file (ad es. `Lezione_Completa_Pipeline_YouTube.ipynb`) in una cartella di progetto.\n",
    "2.  Assicurati che le dipendenze siano installate e la chiave API (se desideri dati reali) sia configurata.\n",
    "3.  Avvia JupyterLab o Jupyter Notebook: `jupyter lab` o `jupyter notebook`.\n",
    "4.  Apri il notebook e esegui le celle in sequenza (solitamente con `Shift + Enter`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bl5n8KxBR4PG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106764,
     "status": "ok",
     "timestamp": 1748878583841,
     "user": {
      "displayName": "Giorgio Ottolina",
      "userId": "00826251580418598435"
     },
     "user_tz": -120
    },
    "id": "bl5n8KxBR4PG",
    "outputId": "b0dca10a-64d4-47ef-da70-64c033862713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
      "Collecting youtube-transcript-api\n",
      "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Collecting jupyterlab\n",
      "  Downloading jupyterlab-4.4.3-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab)\n",
      "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (0.28.1)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (6.17.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (3.1.6)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (5.7.2)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab)\n",
      "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab)\n",
      "  Downloading jupyter_server-2.16.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab)\n",
      "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (24.2)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (75.2.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (6.4.2)\n",
      "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (5.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (7.34.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (6.1.12)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (24.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab) (3.0.2)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
      "Collecting jupyter-client>=6.1.12 (from ipykernel>=6.5.0->jupyterlab)\n",
      "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.22.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab) (4.3.8)\n",
      "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.17.0)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab)\n",
      "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)\n",
      "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.51)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.19.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.25.1)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.13.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.2.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.4)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.11.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.7)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
      "  Downloading types_python_dateutil-2.9.0.20250516-py3-none-any.whl.metadata (2.1 kB)\n",
      "Downloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab-4.4.3-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_server-2.16.0-py3-none-any.whl (386 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
      "Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_python_dateutil-2.9.0.20250516-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, json5, jedi, fqdn, async-lru, youtube-transcript-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jupyter-server-terminals, jupyter-client, arrow, nvidia-cusolver-cu12, isoduration, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 6.1.12\n",
      "    Uninstalling jupyter-client-6.1.12:\n",
      "      Successfully uninstalled jupyter-client-6.1.12\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: jupyter-server\n",
      "    Found existing installation: jupyter-server 1.16.0\n",
      "    Uninstalling jupyter-server-1.16.0:\n",
      "      Successfully uninstalled jupyter-server-1.16.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "notebook 6.5.7 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed arrow-1.3.0 async-lru-2.0.5 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.2 json5-0.12.0 jupyter-client-8.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.16.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.3 jupyterlab-server-2.27.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 overrides-7.7.0 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 types-python-dateutil-2.9.0.20250516 uri-template-1.3.0 youtube-transcript-api-1.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install requests polars youtube-transcript-api sentence-transformers pandas jupyterlab matplotlib accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tcXulradQsA-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1748878902503,
     "user": {
      "displayName": "Giorgio Ottolina",
      "userId": "00826251580418598435"
     },
     "user_tz": -120
    },
    "id": "tcXulradQsA-",
    "outputId": "7ce7f4ea-ca0c-46de-aa7b-9a3a6f3ad184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTube API Key letta correttamente dalla variabile d'ambiente.\n",
      "Configurazione YouTube API Key completata.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Configurazione della YouTube API Key\n",
    "youtube_api_key = os.environ.get(\"YOUTUBE_API_KEY\")\n",
    "if not youtube_api_key:\n",
    "    youtube_api_key = getpass(\"Inserisci la tua YouTube API Key: \")\n",
    "    os.environ[\"YOUTUBE_API_KEY\"] = youtube_api_key  # La imposta per la sessione corrente\n",
    "else:\n",
    "    print(\"YouTube API Key letta correttamente dalla variabile d'ambiente.\")\n",
    "\n",
    "# (Opzionale) Configurazione per OpenAI API Key\n",
    "# openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# if not openai_api_key:\n",
    "#     openai_api_key = getpass(\"Inserisci la tua OpenAI API Key: \")\n",
    "#     os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "# else:\n",
    "#     print(\"OpenAI API Key letta correttamente dalla variabile d'ambiente.\")\n",
    "\n",
    "print(\"Configurazione YouTube API Key completata.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "YOnVoYHaTlAQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1748878907747,
     "user": {
      "displayName": "Giorgio Ottolina",
      "userId": "00826251580418598435"
     },
     "user_tz": -120
    },
    "id": "YOnVoYHaTlAQ",
    "outputId": "c332ed42-265f-4ee5-a9fd-e4fa72ed2b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valore di YOUTUBE_API_KEY in os.environ: AIzaSyAXPOzEm_T-WDf5EAkt0lKW1Va9TJDio4Y\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Valore di YOUTUBE_API_KEY in os.environ:\", os.environ.get(\"YOUTUBE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "KaM60FffUO95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1748879080109,
     "user": {
      "displayName": "Giorgio Ottolina",
      "userId": "00826251580418598435"
     },
     "user_tz": -120
    },
    "id": "KaM60FffUO95",
    "outputId": "01215abd-b540-4ee4-d409-b797ac07ebdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurazione YouTube API Key completata.\n"
     ]
    }
   ],
   "source": [
    "# *** Copia lo stesso valore anche in YT_API_KEY, che è quello che getVideoIDs si aspetta ***\n",
    "os.environ[\"YT_API_KEY\"] = os.environ[\"YOUTUBE_API_KEY\"]\n",
    "\n",
    "print(\"Configurazione YouTube API Key completata.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "markdown_project_structure",
   "metadata": {
    "id": "markdown_project_structure"
   },
   "source": [
    "## 1. Struttura del Progetto e dei Dati\n",
    "\n",
    "Prima di addentrarci nel codice, è utile capire come un progetto di data pipeline potrebbe essere strutturato e come i dati fluiscono attraverso di esso. In uno scenario reale, separeremmo logica, configurazioni e dati.\n",
    "\n",
    "### 1.1. Organizzazione dei File (Esempio)\n",
    "\n",
    "In un progetto più strutturato, potremmo avere una cartella principale (es. `youtube_data_pipeline_project`) con una struttura simile a questa:\n",
    "\n",
    "```\n",
    "youtube_data_pipeline_project/\n",
    "|-- notebooks/                    # Contiene i Jupyter Notebooks come questo\n",
    "|   |-- Lezione_Completa_Pipeline_YouTube.ipynb\n",
    "|-- src/                          # Codice sorgente della pipeline\n",
    "|   |-- functions.py              # Modulo con le funzioni riutilizzabili della pipeline\n",
    "|   |-- data_pipeline.py          # Script principale per eseguire l'intera pipeline (es. da riga di comando)\n",
    "|-- data/                         # Dati grezzi, intermedi e finali (spesso ignorata da Git se i dati sono grandi)\n",
    "|   |-- video-ids.parquet\n",
    "|   |-- video-transcripts.parquet\n",
    "|   |-- video-transcripts-transformed.parquet\n",
    "|   |-- video-index.parquet\n",
    "|-- requirements.txt              # Dipendenze Python del progetto\n",
    "|-- .env                          # (Opzionale, per sviluppo locale) Variabili d'ambiente come YT_API_KEY (DA IGNORARE IN GIT!)\n",
    "|-- .gitignore                    # File per specificare cosa Git deve ignorare (es. .env, data/, __pycache__/)\n",
    "|-- README.md                     # Descrizione del progetto\n",
    "|-- .github/workflows/            # (Per l'automazione) File YAML per GitHub Actions\n",
    "|   |-- youtube_data_pipeline.yml\n",
    "```\n",
    "\n",
    "**Spiegazione:**\n",
    "* **`notebooks/`**: Qui risiedono i notebook per l'analisi esplorativa, la prototipazione e la documentazione interattiva come questa lezione.\n",
    "* **`src/`**: Contiene il codice Python modulare.\n",
    "    * `functions.py`: Definisce le funzioni specifiche per ogni passaggio della pipeline (estrazione dati, trasformazione, ecc.). Questo promuove la riutilizzabilità e la testabilità del codice. Nel nostro notebook, incorporeremo queste funzioni direttamente per chiarezza didattica, ma in un progetto reale sarebbero in questo file separato.\n",
    "    * `data_pipeline.py`: Uno script che importa le funzioni da `functions.py` e le orchestra per eseguire l'intera pipeline dall'inizio alla fine. È utile per l'esecuzione automatizzata.\n",
    "* **`data/`**: Questa cartella è cruciale. È dove vengono salvati tutti i dati generati dalla pipeline. Idealmente, ogni passaggio intermedio salva il suo output qui, tipicamente in formati efficienti come Parquet. Per questo notebook, creeremo una cartella `data` nella stessa directory del notebook.\n",
    "* **`requirements.txt`**: Elenca tutte le librerie Python necessarie per eseguire il progetto, facilitando la creazione di ambienti riproducibili.\n",
    "* **`.env`**: (Opzionale, per sviluppo locale) Un file per memorizzare variabili d'ambiente come la chiave API di YouTube. **Questo file non deve MAI essere committato su Git.**\n",
    "* **`.gitignore`**: Specifica a Git quali file e cartelle ignorare (es. `.venv/`, `__pycache__/`, `data/` se i dati sono troppo grandi o sensibili, `*.env`).\n",
    "* **`README.md`**: Fornisce una descrizione del progetto, come configurarlo ed eseguirlo.\n",
    "* **`.github/workflows/`**: Contiene i file di configurazione YAML per GitHub Actions, usati per automatizzare l'esecuzione della pipeline (vedi Sezione 9).\n",
    "\n",
    "Per questa lezione, semplificheremo leggermente la struttura: le funzioni saranno definite direttamente nel notebook e tutti i file di output verranno salvati in una cartella `data/` creata nella stessa directory di questo notebook.\n",
    "\n",
    "### 1.2. Flusso dei Dati\n",
    "\n",
    "La pipeline che costruiremo seguirà questo flusso di dati:\n",
    "1.  **ID Video e Metadati**: Interrogazione dell'API di YouTube -> `video-ids.parquet`\n",
    "2.  **Trascrizioni**: Lettura da `video-ids.parquet`, interrogazione API trascrizioni -> `video-transcripts.parquet`\n",
    "3.  **Validazione e Trasformazione**: Lettura da `video-transcripts.parquet`, pulizia e standardizzazione -> `video-transcripts-transformed.parquet`\n",
    "4.  **Embedding**: Lettura da `video-transcripts-transformed.parquet`, generazione embedding -> `video-index.parquet` (output finale)\n",
    "\n",
    "L'uso del formato **Parquet** è preferibile per i dati tabellari intermedi e finali perché è un formato colonnare efficiente in termini di spazio e velocità di lettura/scrittura, specialmente con librerie come Polars e Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3031d947",
   "metadata": {
    "id": "3031d947"
   },
   "source": [
    "## 2. Setup Iniziale: Importazioni e Configurazioni\n",
    "\n",
    "Iniziamo importando tutte le librerie Python che utilizzeremo nel corso del notebook e configurando alcuni parametri di base, come la creazione della directory di output per i nostri dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "BhzOFcM2RYy1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16298,
     "status": "ok",
     "timestamp": 1748878357259,
     "user": {
      "displayName": "Giorgio Ottolina",
      "userId": "00826251580418598435"
     },
     "user_tz": -120
    },
    "id": "BhzOFcM2RYy1",
    "outputId": "db6f1e0c-21d9-4838-fae0-29e4b2f7a71a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b61bceb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36877,
     "status": "ok",
     "timestamp": 1748878628985,
     "user": {
      "displayName": "Giorgio Ottolina",
      "userId": "00826251580418598435"
     },
     "user_tz": -120
    },
    "id": "7b61bceb",
    "outputId": "1914da5a-878d-49b5-a764-50733c960532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/content/drive/MyDrive/SIAE/Week 1 - Foundations & Intro GenAI/Day 1 - Welcome & Setup/Esercizi/Soluzioni/6 - Github Actions - DE + Pipeline/data' già esistente.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import polars as pl # Libreria per data manipulation ad alte prestazioni\n",
    "from youtube_transcript_api import YouTubeTranscriptApi # Per scaricare le trascrizioni\n",
    "from sentence_transformers import SentenceTransformer # Per generare embedding testuali\n",
    "import os # Per interazioni con il sistema operativo (es. gestione path)\n",
    "import time # Per misurare i tempi di esecuzione\n",
    "import datetime # Per gestire date e orari\n",
    "\n",
    "# --- Configurazioni Globali ---\n",
    "DATA_DIR = '/content/drive/MyDrive/SIAE/Week 1 - Foundations & Intro GenAI/Day 1 - Welcome & Setup/Esercizi/Soluzioni/6 - Github Actions - DE + Pipeline/data' # Nome della directory dove salveremo i dati\n",
    "YT_CHANNEL_ID = 'UCa9gErQ9AE5jT2DZLjXBIdA' # ID del canale YouTube di Shaw Talebi (esempio)\n",
    "\n",
    "# Creazione della directory 'data' se non esiste già\n",
    "# Qui salveremo i file intermedi e finali della nostra pipeline.\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "    print(f\"Directory '{DATA_DIR}' creata con successo.\")\n",
    "else:\n",
    "    print(f\"Directory '{DATA_DIR}' già esistente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed25f5f",
   "metadata": {
    "id": "9ed25f5f"
   },
   "source": [
    "## 3. Definizione delle Funzioni della Pipeline\n",
    "\n",
    "Per rendere il nostro codice modulare, riutilizzabile e più facile da comprendere, definiamo una serie di funzioni, ognuna responsabile di un compito specifico all'interno della pipeline. In un progetto reale, queste funzioni risiederebbero in un file separato (es. `src/functions.py`).\n",
    "\n",
    "Ogni funzione è documentata per spiegare il suo scopo, i parametri e cosa restituisce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95cf369",
   "metadata": {
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1748878638390,
     "user": {
      "displayName": "Giorgio Ottolina",
      "userId": "00826251580418598435"
     },
     "user_tz": -120
    },
    "id": "d95cf369"
   },
   "outputs": [],
   "source": [
    "# --- Funzioni per l'Interazione con l'API di YouTube ---\n",
    "def getVideoRecords(response: requests.models.Response) -> list:\n",
    "    \"\"\"\n",
    "    Estrae i record video significativi dalla risposta JSON dell'API di Youtube.\n",
    "    Per ogni video, recupera ID, data di pubblicazione e titolo.\n",
    "\n",
    "    Args:\n",
    "        response: L'oggetto Response da una chiamata requests.get all'API di YouTube.\n",
    "\n",
    "    Returns:\n",
    "        Una lista di dizionari, dove ogni dizionario rappresenta un video.\n",
    "    \"\"\"\n",
    "    video_record_list = []\n",
    "    for raw_item in json.loads(response.text)['items']:\n",
    "        # Processa solo item di tipo 'youtube#video'\n",
    "        if raw_item['id']['kind'] != \"youtube#video\":\n",
    "            continue\n",
    "        video_record = {}\n",
    "        video_record['video_id'] = raw_item['id']['videoId']\n",
    "        video_record['datetime'] = raw_item['snippet']['publishedAt']\n",
    "        video_record['title'] = raw_item['snippet']['title']\n",
    "        video_record_list.append(video_record)\n",
    "    return video_record_list\n",
    "\n",
    "def getVideoIDs(channel_id: str, output_path: str = os.path.join(DATA_DIR, 'video-ids.parquet')):\n",
    "    \"\"\"\n",
    "    Recupera tutti gli ID video, le date di pubblicazione e i titoli per un dato canale YouTube\n",
    "    e salva i risultati in un file Parquet.\n",
    "    Gestisce la paginazione per recuperare tutti i video.\n",
    "    Se la chiave API non è fornita, crea un file Parquet segnaposto.\n",
    "\n",
    "    Args:\n",
    "        channel_id: L'ID del canale YouTube da cui estrarre i video.\n",
    "        output_path: Il percorso del file Parquet dove salvare i dati.\n",
    "    \"\"\"\n",
    "    page_token = None\n",
    "    url = 'https://www.googleapis.com/youtube/v3/search'\n",
    "    my_key = os.getenv('YT_API_KEY') # Recupera la chiave API dalla variabile d'ambiente\n",
    "\n",
    "    if not my_key:\n",
    "        print(\"ATTENZIONE: Chiave API di YouTube (YT_API_KEY) non trovata nelle variabili d'ambiente.\")\n",
    "        print(f\"Verranno creati dati segnaposto in '{output_path}'.\")\n",
    "        # Dati segnaposto se la chiave API non è disponibile\n",
    "        placeholder_df = pl.DataFrame({\n",
    "            'video_id': ['esempio_id_1', 'esempio_id_2', 'esempio_id_3'],\n",
    "            'datetime': ['2023-01-01T00:00:00Z', '2023-01-15T10:00:00Z', '2023-02-01T12:30:00Z'],\n",
    "            'title': ['Video Esempio 1 (Segnaposto API)', 'Altro Video Interessante (Segnaposto API)', 'Tutorial Fantastico (Segnaposto API)']\n",
    "        })\n",
    "        placeholder_df.write_parquet(output_path)\n",
    "        print(f\"File segnaposto creato: {output_path}\")\n",
    "        return\n",
    "\n",
    "    video_record_list = []\n",
    "    print(f\"Recupero ID video per il canale: {channel_id}...\")\n",
    "    try:\n",
    "        while page_token != 0: # Il token 0 indica che non ci sono più pagine\n",
    "            params = {\n",
    "                \"key\": my_key,\n",
    "                'channelId': channel_id,\n",
    "                'part': [\"snippet\",\"id\"],\n",
    "                'order': \"date\",\n",
    "                'maxResults': 50, # Massimo consentito per pagina\n",
    "                'pageToken': page_token\n",
    "            }\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status() # Solleva un errore per status HTTP cattivi (4xx o 5xx)\n",
    "\n",
    "            data = json.loads(response.text)\n",
    "            video_record_list.extend(getVideoRecords(response))\n",
    "\n",
    "            page_token = data.get('nextPageToken')\n",
    "            if not page_token: # Se non c'è nextPageToken, abbiamo finito\n",
    "                page_token = 0\n",
    "\n",
    "            print(f\"Recuperati {len(video_record_list)} video finora... Prossima pagina token: {page_token if page_token else 'Nessuna'}\")\n",
    "            time.sleep(0.5) # Cortesia verso l'API, evita di fare troppe richieste ravvicinate\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Errore durante la richiesta API a YouTube: {e}\")\n",
    "        if not video_record_list: # Se non abbiamo raccolto nessun dato e c'è un errore\n",
    "            print(f\"Creazione di un file segnaposto a causa dell'errore API in '{output_path}'.\")\n",
    "            # Crea un DataFrame vuoto con lo schema corretto se l'API fallisce e non ci sono dati\n",
    "            placeholder_df = pl.DataFrame({'video_id': [], 'datetime': [], 'title': []},\n",
    "                                        schema={'video_id': pl.Utf8, 'datetime': pl.Utf8, 'title': pl.Utf8})\n",
    "            placeholder_df.write_parquet(output_path)\n",
    "            return\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Errore durante la decodifica della risposta JSON da YouTube: {e}\")\n",
    "        # Considera una gestione dell'errore simile a quella sopra se necessario\n",
    "        return\n",
    "\n",
    "    if video_record_list:\n",
    "        df_videos = pl.DataFrame(video_record_list)\n",
    "        df_videos.write_parquet(output_path)\n",
    "        print(f\"Totale {len(df_videos)} ID video e metadati salvati in '{output_path}'\")\n",
    "    elif not os.path.exists(output_path): # Se la lista è vuota e non esiste un file segnaposto\n",
    "        print(\"Nessun record video recuperato e nessun file segnaposto esistente. Creazione di un file vuoto.\")\n",
    "        df_empty = pl.DataFrame({'video_id': [], 'datetime': [], 'title': []},\n",
    "                                schema={'video_id': pl.Utf8, 'datetime': pl.Utf8, 'title': pl.Utf8})\n",
    "        df_empty.write_parquet(output_path)\n",
    "        print(f\"File vuoto creato: {output_path}\")\n",
    "\n",
    "# --- Funzioni per la Gestione delle Trascrizioni Video ---\n",
    "def extractTranscriptText(transcript_list_of_dicts: list) -> str:\n",
    "    \"\"\"\n",
    "    Estrae e concatena il testo da una lista di dizionari di trascrizione.\n",
    "    Ogni dizionario nella lista dovrebbe avere una chiave 'text'.\n",
    "\n",
    "    Args:\n",
    "        transcript_list_of_dicts: Lista di dizionari fornita da YouTubeTranscriptApi.\n",
    "\n",
    "    Returns:\n",
    "        Una stringa unica contenente tutto il testo della trascrizione.\n",
    "    \"\"\"\n",
    "    text_list = [part['text'] for part in transcript_list_of_dicts]\n",
    "    return ' '.join(text_list)\n",
    "\n",
    "def getVideoTranscripts(ids_path: str = os.path.join(DATA_DIR, 'video-ids.parquet'),\n",
    "                        output_path: str = os.path.join(DATA_DIR, 'video-transcripts.parquet')):\n",
    "    \"\"\"\n",
    "    Legge gli ID video da un file Parquet, scarica le loro trascrizioni (italiano o inglese)\n",
    "    e salva i risultati (incluso ID, datetime, titolo, trascrizione) in un nuovo file Parquet.\n",
    "    Se una trascrizione non è disponibile, inserisce 'n/d'.\n",
    "\n",
    "    Args:\n",
    "        ids_path: Percorso del file Parquet contenente gli ID video.\n",
    "        output_path: Percorso del file Parquet dove salvare i dati con le trascrizioni.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(ids_path):\n",
    "        print(f\"File degli ID video '{ids_path}' non trovato. Esegui prima getVideoIDs.\")\n",
    "        print(f\"Creazione di un file segnaposto per le trascrizioni in '{output_path}'.\")\n",
    "        # Dati segnaposto se il file degli ID non esiste\n",
    "        placeholder_df = pl.DataFrame({\n",
    "            'video_id': ['esempio_id_1', 'esempio_id_2'],\n",
    "            'datetime': ['2023-01-01T00:00:00Z', '2023-01-15T10:00:00Z'],\n",
    "            'title': ['Video Esempio 1 (Segnaposto Trasc.)', 'Altro Video (Segnaposto Trasc.)'],\n",
    "            'transcript': ['Questa è una trascrizione di esempio (segnaposto).', 'n/d']\n",
    "        })\n",
    "        placeholder_df.write_parquet(output_path)\n",
    "        return\n",
    "\n",
    "    df = pl.read_parquet(ids_path)\n",
    "    if df.is_empty():\n",
    "        print(f\"Il file degli ID video '{ids_path}' è vuoto. Nessuna trascrizione da recuperare.\")\n",
    "        # Aggiunge una colonna 'transcript' vuota se il DataFrame degli ID è vuoto ma esiste\n",
    "        df = df.with_columns(pl.lit(None).cast(pl.Utf8).alias(\"transcript\"))\n",
    "        df.write_parquet(output_path)\n",
    "        print(f\"File vuoto delle trascrizioni video creato in '{output_path}'.\")\n",
    "        return\n",
    "\n",
    "    transcript_text_list = []\n",
    "    total_videos = len(df)\n",
    "    print(f\"Recupero delle trascrizioni per {total_videos} video...\")\n",
    "\n",
    "    for i, video_id in enumerate(df['video_id']):\n",
    "        try:\n",
    "            # Richiede la trascrizione in italiano, fallback in inglese\n",
    "            transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['it', 'en'])\n",
    "            transcript_text = extractTranscriptText(transcript_list)\n",
    "        except Exception as e:\n",
    "            # print(f\"  ATTENZIONE: Impossibile recuperare la trascrizione per {video_id}: {e}\")\n",
    "            transcript_text = \"n/d\" # Not defined/Not available\n",
    "        transcript_text_list.append(transcript_text)\n",
    "\n",
    "        if (i + 1) % 10 == 0 or (i + 1) == total_videos: # Logga ogni 10 video o all'ultimo video\n",
    "            print(f\"  Elaborati {i+1}/{total_videos} video...\")\n",
    "\n",
    "    df = df.with_columns(pl.Series(name=\"transcript\", values=transcript_text_list))\n",
    "    df.write_parquet(output_path)\n",
    "    print(f\"Trascrizioni video salvate in '{output_path}'.\")\n",
    "\n",
    "# --- Funzioni per la Pulizia e Trasformazione dei Dati ---\n",
    "def handleSpecialStrings(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Pulisce caratteri speciali HTML-encoded e altre stringhe specifiche dalle colonne 'title' e 'transcript'.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame Polars contenente le colonne 'title' e/o 'transcript'.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame Polars con le stringhe pulite.\n",
    "    \"\"\"\n",
    "    # Mappatura dei caratteri speciali comuni e loro sostituzioni\n",
    "    replacements = {\n",
    "        '&#39;': \"'\",      # Apostrofo HTML entity\n",
    "        '&amp;': \"&\",      # E commerciale HTML entity\n",
    "        '&quot;': '\"',   # Virgolette HTML entity\n",
    "        '“': '\"',        # Virgolette doppie aperte\n",
    "        '”': '\"',        # Virgolette doppie chiuse\n",
    "        '‘': \"'\",        # Virgoletta singola aperta\n",
    "        '’': \"'\",        # Virgoletta singola chiusa\n",
    "        '…': \"...\",      # Puntini di sospensione\n",
    "        'Sha ': 'Shaw ', # Correzione specifica (esempio)\n",
    "        'SHA ': 'Shaw '  # Correzione specifica (esempio)\n",
    "    }\n",
    "    columns_to_clean = ['title', 'transcript']\n",
    "\n",
    "    for col_name in columns_to_clean:\n",
    "        if col_name in df.columns:\n",
    "            print(f\"Pulizia caratteri speciali nella colonna: {col_name}\")\n",
    "            # Applica tutte le sostituzioni in una volta per efficienza se possibile\n",
    "            # Polars permette .str.replace_all con più pattern, ma qui lo facciamo iterativamente per chiarezza\n",
    "            temp_col = df[col_name]\n",
    "            for special_str, replacement_str in replacements.items():\n",
    "                temp_col = temp_col.str.replace_all(special_str, replacement_str)\n",
    "            df = df.with_columns(temp_col.alias(col_name))\n",
    "    return df\n",
    "\n",
    "def setDatatypes(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Converte la colonna 'datetime' da stringa a tipo pl.Datetime.\n",
    "    Gestisce potenziali errori durante la conversione.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame Polars con una colonna 'datetime' di tipo stringa.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame Polars con la colonna 'datetime' convertita.\n",
    "    \"\"\"\n",
    "    if 'datetime' in df.columns:\n",
    "        print(\"Conversione della colonna 'datetime' al tipo pl.Datetime.\")\n",
    "        try:\n",
    "            # Tenta la conversione, specificando il formato atteso. 'strict=False' permette una certa flessibilità.\n",
    "            df = df.with_columns(pl.col('datetime').str.to_datetime(format=\"%Y-%m-%dT%H:%M:%SZ\", strict=False).cast(pl.Datetime))\n",
    "        except Exception as e:\n",
    "            print(f\"Errore durante la conversione della colonna 'datetime': {e}.\")\n",
    "            print(\"La colonna 'datetime' potrebbe rimanere di tipo stringa o contenere valori nulli dove la conversione è fallita.\")\n",
    "    return df\n",
    "\n",
    "def transformData(input_path: str = os.path.join(DATA_DIR, 'video-transcripts.parquet'),\n",
    "                  output_path: str = os.path.join(DATA_DIR, 'video-transcripts-transformed.parquet')):\n",
    "    \"\"\"\n",
    "    Applica trasformazioni ai dati (pulizia stringhe, conversione tipi) letti da un file Parquet\n",
    "    e salva il risultato in un nuovo file Parquet.\n",
    "\n",
    "    Args:\n",
    "        input_path: Percorso del file Parquet di input.\n",
    "        output_path: Percorso del file Parquet di output per i dati trasformati.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"File '{input_path}' non trovato. Esegui prima getVideoTranscripts.\")\n",
    "        print(f\"Creazione di un file segnaposto per i dati trasformati in '{output_path}'.\")\n",
    "        # Dati segnaposto se il file di input non esiste\n",
    "        placeholder_df = pl.DataFrame({\n",
    "            'video_id': ['esempio_id_1'],\n",
    "            'datetime': ['2023-01-01T00:00:00Z'],\n",
    "            'title': ['Titolo &amp; Esempio (Segnaposto Transf.)'],\n",
    "            'transcript': ['Testo con caratteri &#39;speciali&#39; (segnaposto transf).']\n",
    "        })\n",
    "        placeholder_df = handleSpecialStrings(placeholder_df) # Applica comunque la pulizia\n",
    "        placeholder_df = setDatatypes(placeholder_df)       # e la conversione tipi\n",
    "        placeholder_df.write_parquet(output_path)\n",
    "        return\n",
    "\n",
    "    df = pl.read_parquet(input_path)\n",
    "    if df.is_empty():\n",
    "        print(f\"Il file '{input_path}' è vuoto. Nessun dato da trasformare.\")\n",
    "        df.write_parquet(output_path) # Salva un file vuoto con lo schema corretto\n",
    "        print(f\"File vuoto dei dati trasformati creato in '{output_path}'.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Applicazione trasformazioni (pulizia stringhe, tipi di dati) al file: {input_path}\")\n",
    "    df = handleSpecialStrings(df)\n",
    "    df = setDatatypes(df)\n",
    "\n",
    "    df.write_parquet(output_path)\n",
    "    print(f\"Dati trasformati salvati in '{output_path}'.\")\n",
    "\n",
    "# --- Funzione per la Creazione di Embedding Testuali ---\n",
    "def createTextEmbeddings(input_path: str = os.path.join(DATA_DIR, 'video-transcripts-transformed.parquet'),\n",
    "                         output_path: str = os.path.join(DATA_DIR, 'video-index.parquet')):\n",
    "    \"\"\"\n",
    "    Carica i dati trasformati, genera embedding per le colonne 'title' e 'transcript'\n",
    "    utilizzando un modello SentenceTransformer, e salva il DataFrame risultante (video index)\n",
    "    in un file Parquet.\n",
    "\n",
    "    Args:\n",
    "        input_path: Percorso del file Parquet con i dati trasformati.\n",
    "        output_path: Percorso del file Parquet dove salvare l'indice video con gli embedding.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"File dati trasformati '{input_path}' non trovato. Esegui prima transformData.\")\n",
    "        print(f\"Creazione di un file segnaposto per l'indice video in '{output_path}'.\")\n",
    "        # Dati segnaposto se il file di input non esiste\n",
    "        placeholder_df = pl.DataFrame({\n",
    "            'video_id': ['esempio_id_1'],\n",
    "            'datetime': [datetime.datetime(2023,1,1)], # Usa un vero datetime per coerenza\n",
    "            'title': ['Titolo Pulito (Segnaposto Emb.)'],\n",
    "            'transcript': ['Trascrizione pulita (segnaposto emb).']\n",
    "        })\n",
    "        # Nota: Non generiamo embedding fittizi qui per semplicità, ma potresti farlo.\n",
    "        placeholder_df.write_parquet(output_path)\n",
    "        return\n",
    "\n",
    "    df = pl.read_parquet(input_path)\n",
    "    if df.is_empty():\n",
    "        print(f\"Il file '{input_path}' è vuoto. Nessun dato per creare embedding.\")\n",
    "        df.write_parquet(output_path) # Salva un file vuoto con lo schema corretto\n",
    "        print(f\"File vuoto dell'indice video creato in '{output_path}'.\")\n",
    "        return\n",
    "\n",
    "    # Modello SentenceTransformer pre-addestrato. 'all-MiniLM-L6-v2' è un buon compromesso tra performance e dimensione.\n",
    "    model_name = 'all-MiniLM-L6-v2'\n",
    "    print(f\"Caricamento del modello SentenceTransformer: '{model_name}'...\")\n",
    "    try:\n",
    "        model = SentenceTransformer(model_name)\n",
    "    except Exception as e:\n",
    "        print(f\"ERRORE CRITICO: Impossibile caricare il modello SentenceTransformer '{model_name}': {e}.\")\n",
    "        print(\"La generazione degli embedding verrà saltata. Controlla la connessione internet o l'installazione del modello.\")\n",
    "        df.write_parquet(output_path) # Salva il df senza embedding\n",
    "        return\n",
    "\n",
    "    columns_to_embed = ['title', 'transcript']\n",
    "    print(f\"Generazione degli embedding per le colonne: {', '.join(columns_to_embed)}...\")\n",
    "\n",
    "    df_final_parts = [df] # Lista per contenere il DataFrame originale e i DataFrame degli embedding\n",
    "\n",
    "    for column_name in columns_to_embed:\n",
    "        if column_name not in df.columns or df[column_name].is_empty() or df[column_name].null_count() == len(df[column_name]):\n",
    "            print(f\"  ATTENZIONE: Colonna '{column_name}' mancante, vuota o con tutti valori null. Embedding saltato per questa colonna.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  Processando colonna: '{column_name}'...\")\n",
    "        # Sostituisce i null con stringa vuota prima di generare embedding per evitare errori\n",
    "        texts_to_embed = df[column_name].fill_null(\"\").to_list()\n",
    "\n",
    "        if not texts_to_embed:\n",
    "            print(f\"  Nessun dato testuale valido da cui generare embedding per la colonna '{column_name}'.\")\n",
    "            continue\n",
    "\n",
    "        # Genera gli embedding. show_progress_bar è utile per dataset grandi.\n",
    "        embedding_arr = model.encode(texts_to_embed, show_progress_bar=True)\n",
    "        embedding_dim = embedding_arr.shape[1]\n",
    "\n",
    "        # Crea nomi di colonna per gli embedding (es. title_embedding_0, title_embedding_1, ...)\n",
    "        embedding_col_names = [f\"{column_name}_embedding_{i}\" for i in range(embedding_dim)]\n",
    "\n",
    "        # Crea un DataFrame Polars con gli embedding\n",
    "        df_embedding = pl.DataFrame(embedding_arr, schema=embedding_col_names)\n",
    "        df_final_parts.append(df_embedding)\n",
    "        print(f\"  Embedding per '{column_name}' generati (dimensione: {embedding_dim}).\")\n",
    "\n",
    "    # Concatena il DataFrame originale con i nuovi DataFrame di embedding orizzontalmente\n",
    "    if len(df_final_parts) > 1:\n",
    "        df_with_embeddings = pl.concat(df_final_parts, how='horizontal')\n",
    "    else: # Se nessun embedding è stato generato (es. colonne mancanti o vuote)\n",
    "        df_with_embeddings = df\n",
    "\n",
    "    df_with_embeddings.write_parquet(output_path)\n",
    "    print(f\"Indice video con embedding salvato in '{output_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation_intro_markdown",
   "metadata": {
    "id": "validation_intro_markdown"
   },
   "source": [
    "## 4. Validazione dei Dati e Giustificazione delle Trasformazioni\n",
    "\n",
    "Prima di procedere con trasformazioni complesse o la generazione di embedding, è fondamentale **validare i dati** raccolti. Questa fase ci permette di capire la qualità dei dati, identificare problemi (es. valori mancanti, formati non corretti, caratteri speciali) e, di conseguenza, giustificare i passaggi di pulizia e trasformazione successivi.\n",
    "\n",
    "Useremo il file `video-transcripts.parquet` (generato dal Passo 2 dell'esecuzione della pipeline, che vedremo più avanti) come esempio per questa fase di ispezione. In un flusso reale, questa validazione informerebbe la progettazione delle funzioni `handleSpecialStrings` e `setDatatypes`.\n",
    "\n",
    "Le operazioni di validazione comuni includono:\n",
    "* **Controllo dimensionale**: Quante righe e colonne abbiamo? (`df.shape`)\n",
    "* **Controllo dei tipi di dato**: Le colonne hanno il tipo di dato atteso? (`df.dtypes` o `df.schema` in Polars)\n",
    "* **Valori mancanti**: Ci sono valori nulli o mancanti e come sono distribuiti? (`df.null_count()`)\n",
    "* **Unicità**: Quanti valori unici ci sono per colonna? Ci sono duplicati inattesi? (`df.n_unique()`)\n",
    "* **Statistiche descrittive**: Per colonne numeriche (min, max, media, mediana) e per colonne testuali (lunghezza stringhe, pattern comuni).\n",
    "* **Ispezione di stringhe particolari**: Ricerca di caratteri speciali, encoding errati, ecc.\n",
    "\n",
    "Eseguiremo alcune di queste validazioni sul file che conterrà le trascrizioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "validation_code_cell",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1748878652474,
     "user": {
      "displayName": "Giorgio Ottolina",
      "userId": "00826251580418598435"
     },
     "user_tz": -120
    },
    "id": "validation_code_cell",
    "outputId": "9fcd2827-142b-41b2-c926-6e3fa158eb9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '/content/drive/MyDrive/SIAE/Week 1 - Foundations & Intro GenAI/Day 1 - Welcome & Setup/Esercizi/Soluzioni/6 - Github Actions - DE + Pipeline/data/video-transcripts.parquet' non trovato. Eseguire prima il Passo 2 della pipeline (getVideoTranscripts).\n",
      "La validazione sarà saltata. Le funzioni di trasformazione gestiranno la creazione di file segnaposto se necessario.\n"
     ]
    }
   ],
   "source": [
    "path_video_transcripts_for_validation = os.path.join(DATA_DIR, 'video-transcripts.parquet')\n",
    "\n",
    "# Assicuriamoci che il file esista (potrebbe essere stato creato con dati segnaposto se l'API non era disponibile)\n",
    "if os.path.exists(path_video_transcripts_for_validation):\n",
    "    print(f\"Lettura del file '{path_video_transcripts_for_validation}' per la validazione...\\n\")\n",
    "    df_validate = pl.read_parquet(path_video_transcripts_for_validation)\n",
    "\n",
    "    if not df_validate.is_empty():\n",
    "        print(\"--- Informazioni Generali ---\")\n",
    "        print(f\"Forma del DataFrame (righe, colonne): {df_validate.shape}\")\n",
    "        print(f\"Numero di righe uniche: {df_validate.n_unique()}\\n\")\n",
    "\n",
    "        print(\"--- Schema e Tipi di Dato Iniziali ---\")\n",
    "        print(df_validate.schema) # Mostra i tipi di dato attuali\n",
    "        # Osservazione: 'datetime' è probabilmente Utf8 (stringa) e necessita conversione.\n",
    "\n",
    "        print(\"\\n--- Conteggio Valori Nulli per Colonna ---\")\n",
    "        print(df_validate.null_count())\n",
    "        # Osservazione: La colonna 'transcript' potrebbe avere nulli se alcune trascrizioni non sono state trovate ('n/d').\n",
    "\n",
    "        print(\"\\n--- Valori Unici per Colonna ---\")\n",
    "        for col_name in df_validate.columns:\n",
    "            print(f\"N. valori unici in '{col_name}': {df_validate[col_name].n_unique()}\")\n",
    "        # Osservazione: Se n. unico di 'video_id' < numero righe totali, ci sono duplicati.\n",
    "        # 'transcript' potrebbe avere meno valori unici di 'video_id' se più video hanno la stessa trascrizione (improbabile) o più video hanno 'n/d'.\n",
    "\n",
    "        print(\"\\n--- Ispezione Primi Titoli per Caratteri Speciali ---\")\n",
    "        if 'title' in df_validate.columns:\n",
    "            print(df_validate.select(pl.col('title')).head())\n",
    "            # Osservazione: Cercare entità HTML come '&amp;', '&#39;', ecc. che necessitano pulizia.\n",
    "            # La funzione handleSpecialStrings si occuperà di questo.\n",
    "        else:\n",
    "            print(\"Colonna 'title' non presente per l'ispezione.\")\n",
    "\n",
    "        # Validazione lunghezza trascrizioni (opzionale, può essere fatto dopo la trasformazione)\n",
    "        # if 'transcript' in df_validate.columns:\n",
    "        #     df_validate = df_validate.with_columns(df_validate['transcript'].str.len_chars().alias('transcript_length'))\n",
    "        #     print(\"\\n--- Statistiche Lunghezza Trascrizioni ---\")\n",
    "        #     print(df_validate.select(pl.col('transcript_length')).describe())\n",
    "        #     # plt.hist(df_validate['transcript_length'].drop_nulls()) # Richiede matplotlib\n",
    "        #     # plt.title('Distribuzione Lunghezza Trascrizioni')\n",
    "        #     # plt.xlabel('Lunghezza')\n",
    "        #     # plt.ylabel('Frequenza')\n",
    "        #     # plt.show()\n",
    "\n",
    "        print(\"\\n--- Conclusione Validazione Preliminare ---\")\n",
    "        print(\"Questa ispezione preliminare ci mostra la necessità di:\")\n",
    "        print(\"1. Convertire la colonna 'datetime' in un formato data/ora effettivo.\")\n",
    "        print(\"2. Gestire i caratteri speciali nei titoli e nelle trascrizioni.\")\n",
    "        print(\"3. Assicurare una gestione coerente dei valori mancanti (es. 'n/d' per le trascrizioni).\")\n",
    "        print(\"Le funzioni `setDatatypes` e `handleSpecialStrings` nella pipeline sono progettate per affrontare questi problemi.\")\n",
    "    else:\n",
    "        print(f\"Il file '{path_video_transcripts_for_validation}' è vuoto. Impossibile eseguire la validazione.\")\n",
    "else:\n",
    "    print(f\"File '{path_video_transcripts_for_validation}' non trovato. Eseguire prima il Passo 2 della pipeline (getVideoTranscripts).\")\n",
    "    print(\"La validazione sarà saltata. Le funzioni di trasformazione gestiranno la creazione di file segnaposto se necessario.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75520cb",
   "metadata": {
    "id": "a75520cb"
   },
   "source": [
    "## 5. Esecuzione della Pipeline Completa\n",
    "\n",
    "Ora che tutte le funzioni necessarie sono state definite e abbiamo compreso l'importanza della validazione, possiamo eseguire la pipeline passo dopo passo. Misureremo anche il tempo di esecuzione di ciascun passaggio principale per monitorare le performance.\n",
    "\n",
    "Ogni passaggio leggerà i dati dal file Parquet generato dal passaggio precedente e salverà il proprio output in un nuovo file Parquet, seguendo il flusso descritto nella Sezione 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c9a3f0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "7c50c76efa314a70972b7f6dce86aaab",
      "5c2c6ed73c454b41bf7d3dd922309dd2",
      "38455d27830f44aba12460b2ea062413",
      "17b675bbfd9d49c28b29b20c474e9d66",
      "6f4d3bd95408460fb00774dc0c034efe",
      "d97f981f0a2a4fd1925f6a969c2218ae",
      "915b4e7c0cdc4d24a4b47db085933fea",
      "6f2db9b9d6af4e36a94244139f37fb03",
      "cb5a1d2dca9b468da8c4a4cf11e35521",
      "33e9ca2fc0bf4f408035dc8df0c5a8f9",
      "40a9581e887a4b18bbc04068315e3409",
      "4bc4f5aadbad45d08b8a0e6906599bdc",
      "9f9c3e28e9a0456d8a2bb0107481f2bf",
      "88b5b010c28c47f98f791393197f2f3c",
      "7ba77796f73143789550b810ef04ad96",
      "f6e0ef0842fc49cd9242f033f02e1c16",
      "f12497ac20f247e0a570b70cf2db5d65",
      "f7fc22cfd0744b2e802828e5978dedb6",
      "3659262f9ecc4d829698fef4e2616050",
      "db118d2048b844eab6f786050a6828cc",
      "671b9a267413483c8e4979d57bdbca14",
      "463290d01f1f46c3bdd6c6c0b2465835"
     ]
    },
    "executionInfo": {
     "elapsed": 95591,
     "status": "ok",
     "timestamp": 1748879354952,
     "user": {
      "displayName": "Giorgio Ottolina",
      "userId": "00826251580418598435"
     },
     "user_tz": -120
    },
    "id": "8c9a3f0e",
    "outputId": "0c888754-7f74-4eb9-a355-a989ca8f9a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIZIO PIPELINE DATI YOUTUBE\n",
      "Ora di inizio: 2025-06-02 15:47:39\n",
      "----------------------------------------------------------------------\n",
      "Passo 1: Estrazione degli ID Video e Metadati\n",
      "Recupero ID video per il canale: UCa9gErQ9AE5jT2DZLjXBIdA...\n",
      "Recuperati 48 video finora... Prossima pagina token: CDIQAA\n",
      "Recuperati 96 video finora... Prossima pagina token: CGQQAA\n",
      "Recuperati 139 video finora... Prossima pagina token: Nessuna\n",
      "Totale 139 ID video e metadati salvati in '/content/drive/MyDrive/SIAE/Week 1 - Foundations & Intro GenAI/Day 1 - Welcome & Setup/Esercizi/Soluzioni/6 - Github Actions - DE + Pipeline/data/video-ids.parquet'\n",
      "---> Passo 1 completato in 2.63 secondi.\n",
      "\n",
      "Passo 2: Estrazione delle Trascrizioni Video\n",
      "Recupero delle trascrizioni per 139 video...\n",
      "  Elaborati 10/139 video...\n",
      "  Elaborati 20/139 video...\n",
      "  Elaborati 30/139 video...\n",
      "  Elaborati 40/139 video...\n",
      "  Elaborati 50/139 video...\n",
      "  Elaborati 60/139 video...\n",
      "  Elaborati 70/139 video...\n",
      "  Elaborati 80/139 video...\n",
      "  Elaborati 90/139 video...\n",
      "  Elaborati 100/139 video...\n",
      "  Elaborati 110/139 video...\n",
      "  Elaborati 120/139 video...\n",
      "  Elaborati 130/139 video...\n",
      "  Elaborati 139/139 video...\n",
      "Trascrizioni video salvate in '/content/drive/MyDrive/SIAE/Week 1 - Foundations & Intro GenAI/Day 1 - Welcome & Setup/Esercizi/Soluzioni/6 - Github Actions - DE + Pipeline/data/video-transcripts.parquet'.\n",
      "---> Passo 2 completato in 90.25 secondi.\n",
      "\n",
      "Passo 3: Validazione (già discussa), Trasformazione e Pulizia dei Dati\n",
      "Applicazione trasformazioni (pulizia stringhe, tipi di dati) al file: /content/drive/MyDrive/SIAE/Week 1 - Foundations & Intro GenAI/Day 1 - Welcome & Setup/Esercizi/Soluzioni/6 - Github Actions - DE + Pipeline/data/video-transcripts.parquet\n",
      "Pulizia caratteri speciali nella colonna: title\n",
      "Pulizia caratteri speciali nella colonna: transcript\n",
      "Conversione della colonna 'datetime' al tipo pl.Datetime.\n",
      "Dati trasformati salvati in '/content/drive/MyDrive/SIAE/Week 1 - Foundations & Intro GenAI/Day 1 - Welcome & Setup/Esercizi/Soluzioni/6 - Github Actions - DE + Pipeline/data/video-transcripts-transformed.parquet'.\n",
      "---> Passo 3 completato in 0.05 secondi.\n",
      "\n",
      "Passo 4: Generazione degli Embedding Testuali\n",
      "Caricamento del modello SentenceTransformer: 'all-MiniLM-L6-v2'...\n",
      "Generazione degli embedding per le colonne: title, transcript...\n",
      "  Processando colonna: 'title'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c50c76efa314a70972b7f6dce86aaab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embedding per 'title' generati (dimensione: 384).\n",
      "  Processando colonna: 'transcript'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc4f5aadbad45d08b8a0e6906599bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embedding per 'transcript' generati (dimensione: 384).\n",
      "Indice video con embedding salvato in '/content/drive/MyDrive/SIAE/Week 1 - Foundations & Intro GenAI/Day 1 - Welcome & Setup/Esercizi/Soluzioni/6 - Github Actions - DE + Pipeline/data/video-index.parquet'.\n",
      "---> Passo 4 completato in 2.66 secondi.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "FINE PIPELINE DATI YOUTUBE. Tempo totale esecuzione: 95.59 secondi.\n",
      "Ora di fine: 2025-06-02 15:49:14\n"
     ]
    }
   ],
   "source": [
    "print(\"INIZIO PIPELINE DATI YOUTUBE\")\n",
    "pipeline_start_time = time.time()\n",
    "print(f\"Ora di inizio: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Passo 1: Estrazione degli ID Video e Metadati\")\n",
    "step1_start_time = time.time()\n",
    "path_video_ids = os.path.join(DATA_DIR, 'video-ids.parquet')\n",
    "# Eseguiamo la funzione per ottenere gli ID video. `YT_CHANNEL_ID` è definito nelle configurazioni globali.\n",
    "getVideoIDs(channel_id=YT_CHANNEL_ID, output_path=path_video_ids)\n",
    "step1_end_time = time.time()\n",
    "print(f\"---> Passo 1 completato in {round(step1_end_time - step1_start_time, 2)} secondi.\\n\")\n",
    "\n",
    "print(\"Passo 2: Estrazione delle Trascrizioni Video\")\n",
    "step2_start_time = time.time()\n",
    "path_video_transcripts = os.path.join(DATA_DIR, 'video-transcripts.parquet')\n",
    "# Usiamo il file degli ID video generato nel Passo 1 come input\n",
    "getVideoTranscripts(ids_path=path_video_ids, output_path=path_video_transcripts)\n",
    "step2_end_time = time.time()\n",
    "print(f\"---> Passo 2 completato in {round(step2_end_time - step2_start_time, 2)} secondi.\\n\")\n",
    "\n",
    "print(\"Passo 3: Validazione (già discussa), Trasformazione e Pulizia dei Dati\")\n",
    "# La validazione è stata discussa nella Sezione 4.\n",
    "# Ora applichiamo le trasformazioni basate su quelle osservazioni.\n",
    "step3_start_time = time.time()\n",
    "path_video_transcripts_transformed = os.path.join(DATA_DIR, 'video-transcripts-transformed.parquet')\n",
    "# Usiamo il file delle trascrizioni generato nel Passo 2 come input\n",
    "transformData(input_path=path_video_transcripts, output_path=path_video_transcripts_transformed)\n",
    "step3_end_time = time.time()\n",
    "print(f\"---> Passo 3 completato in {round(step3_end_time - step3_start_time, 2)} secondi.\\n\")\n",
    "\n",
    "print(\"Passo 4: Generazione degli Embedding Testuali\")\n",
    "step4_start_time = time.time()\n",
    "path_video_index = os.path.join(DATA_DIR, 'video-index.parquet')\n",
    "# Usiamo il file trasformato generato nel Passo 3 come input\n",
    "createTextEmbeddings(input_path=path_video_transcripts_transformed, output_path=path_video_index)\n",
    "step4_end_time = time.time()\n",
    "print(f\"---> Passo 4 completato in {round(step4_end_time - step4_start_time, 2)} secondi.\\n\")\n",
    "\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "pipeline_end_time = time.time()\n",
    "print(f\"FINE PIPELINE DATI YOUTUBE. Tempo totale esecuzione: {round(pipeline_end_time - pipeline_start_time, 2)} secondi.\")\n",
    "print(f\"Ora di fine: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f337bd",
   "metadata": {
    "id": "81f337bd"
   },
   "source": [
    "## 6. Ispezione dei Risultati Finali\n",
    "\n",
    "Dopo aver eseguito l'intera pipeline, è fondamentale ispezionare l'output finale (`data/video-index.parquet`) per assicurarsi che i dati siano stati elaborati come previsto e che gli embedding siano stati aggiunti.\n",
    "\n",
    "Questo file rappresenta il nostro \"indice video\", pronto per essere utilizzato in applicazioni di ricerca semantica, raccomandazione o altre analisi basate sul contenuto testuale dei video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2afccc1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 116,
     "status": "ok",
     "timestamp": 1748879370566,
     "user": {
      "displayName": "Giorgio Ottolina",
      "userId": "00826251580418598435"
     },
     "user_tz": -120
    },
    "id": "2afccc1a",
    "outputId": "ffed4497-c988-4d1a-d3bf-f2df86e7a3e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ispezione del file di output finale: '/content/drive/MyDrive/SIAE/Week 1 - Foundations & Intro GenAI/Day 1 - Welcome & Setup/Esercizi/Soluzioni/6 - Github Actions - DE + Pipeline/data/video-index.parquet'\n",
      "\n",
      "--- Prime 5 righe del DataFrame finale ---\n",
      "shape: (5, 5)\n",
      "┌─────────────┬─────────────────────┬────────────────────────────┬────────────┬────────────────────┐\n",
      "│ video_id    ┆ datetime            ┆ title                      ┆ transcript ┆ transcript_preview │\n",
      "│ ---         ┆ ---                 ┆ ---                        ┆ ---        ┆ ---                │\n",
      "│ str         ┆ datetime[μs]        ┆ str                        ┆ str        ┆ str                │\n",
      "╞═════════════╪═════════════════════╪════════════════════════════╪════════════╪════════════════════╡\n",
      "│ nSH2vZjb2TA ┆ 2025-06-01 15:01:13 ┆ My PhD Defense [Applied    ┆ n/d        ┆ n/d                │\n",
      "│             ┆                     ┆ Physic…                    ┆            ┆                    │\n",
      "│ nPQkBGf55YA ┆ 2025-05-25 15:01:12 ┆ 30 AI Buzzwords Explained  ┆ n/d        ┆ n/d                │\n",
      "│             ┆                     ┆ For …                      ┆            ┆                    │\n",
      "│ OLmKFj-_5Uw ┆ 2025-05-18 15:00:40 ┆ AI Essentials for          ┆ n/d        ┆ n/d                │\n",
      "│             ┆                     ┆ Entrepreneur…              ┆            ┆                    │\n",
      "│ BUTjcAjfMgY ┆ 2025-05-11 15:00:27 ┆ ML Foundations for AI      ┆ n/d        ┆ n/d                │\n",
      "│             ┆                     ┆ Engineer…                  ┆            ┆                    │\n",
      "│ uItWjWjH_Rs ┆ 2025-05-04 15:01:18 ┆ How I (Vibe) Code with     ┆ n/d        ┆ n/d                │\n",
      "│             ┆                     ┆ Cursor …                   ┆            ┆                    │\n",
      "└─────────────┴─────────────────────┴────────────────────────────┴────────────┴────────────────────┘\n",
      "\n",
      "--- Schema del DataFrame finale (tipi di dati) ---\n",
      "Schema([('video_id', String), ('datetime', Datetime(time_unit='us', time_zone=None)), ('title', String), ('transcript', String), ('title_embedding_0', Float32), ('title_embedding_1', Float32), ('title_embedding_2', Float32), ('title_embedding_3', Float32), ('title_embedding_4', Float32), ('title_embedding_5', Float32), ('title_embedding_6', Float32), ('title_embedding_7', Float32), ('title_embedding_8', Float32), ('title_embedding_9', Float32), ('title_embedding_10', Float32), ('title_embedding_11', Float32), ('title_embedding_12', Float32), ('title_embedding_13', Float32), ('title_embedding_14', Float32), ('title_embedding_15', Float32), ('title_embedding_16', Float32), ('title_embedding_17', Float32), ('title_embedding_18', Float32), ('title_embedding_19', Float32), ('title_embedding_20', Float32), ('title_embedding_21', Float32), ('title_embedding_22', Float32), ('title_embedding_23', Float32), ('title_embedding_24', Float32), ('title_embedding_25', Float32), ('title_embedding_26', Float32), ('title_embedding_27', Float32), ('title_embedding_28', Float32), ('title_embedding_29', Float32), ('title_embedding_30', Float32), ('title_embedding_31', Float32), ('title_embedding_32', Float32), ('title_embedding_33', Float32), ('title_embedding_34', Float32), ('title_embedding_35', Float32), ('title_embedding_36', Float32), ('title_embedding_37', Float32), ('title_embedding_38', Float32), ('title_embedding_39', Float32), ('title_embedding_40', Float32), ('title_embedding_41', Float32), ('title_embedding_42', Float32), ('title_embedding_43', Float32), ('title_embedding_44', Float32), ('title_embedding_45', Float32), ('title_embedding_46', Float32), ('title_embedding_47', Float32), ('title_embedding_48', Float32), ('title_embedding_49', Float32), ('title_embedding_50', Float32), ('title_embedding_51', Float32), ('title_embedding_52', Float32), ('title_embedding_53', Float32), ('title_embedding_54', Float32), ('title_embedding_55', Float32), ('title_embedding_56', Float32), ('title_embedding_57', Float32), ('title_embedding_58', Float32), ('title_embedding_59', Float32), ('title_embedding_60', Float32), ('title_embedding_61', Float32), ('title_embedding_62', Float32), ('title_embedding_63', Float32), ('title_embedding_64', Float32), ('title_embedding_65', Float32), ('title_embedding_66', Float32), ('title_embedding_67', Float32), ('title_embedding_68', Float32), ('title_embedding_69', Float32), ('title_embedding_70', Float32), ('title_embedding_71', Float32), ('title_embedding_72', Float32), ('title_embedding_73', Float32), ('title_embedding_74', Float32), ('title_embedding_75', Float32), ('title_embedding_76', Float32), ('title_embedding_77', Float32), ('title_embedding_78', Float32), ('title_embedding_79', Float32), ('title_embedding_80', Float32), ('title_embedding_81', Float32), ('title_embedding_82', Float32), ('title_embedding_83', Float32), ('title_embedding_84', Float32), ('title_embedding_85', Float32), ('title_embedding_86', Float32), ('title_embedding_87', Float32), ('title_embedding_88', Float32), ('title_embedding_89', Float32), ('title_embedding_90', Float32), ('title_embedding_91', Float32), ('title_embedding_92', Float32), ('title_embedding_93', Float32), ('title_embedding_94', Float32), ('title_embedding_95', Float32), ('title_embedding_96', Float32), ('title_embedding_97', Float32), ('title_embedding_98', Float32), ('title_embedding_99', Float32), ('title_embedding_100', Float32), ('title_embedding_101', Float32), ('title_embedding_102', Float32), ('title_embedding_103', Float32), ('title_embedding_104', Float32), ('title_embedding_105', Float32), ('title_embedding_106', Float32), ('title_embedding_107', Float32), ('title_embedding_108', Float32), ('title_embedding_109', Float32), ('title_embedding_110', Float32), ('title_embedding_111', Float32), ('title_embedding_112', Float32), ('title_embedding_113', Float32), ('title_embedding_114', Float32), ('title_embedding_115', Float32), ('title_embedding_116', Float32), ('title_embedding_117', Float32), ('title_embedding_118', Float32), ('title_embedding_119', Float32), ('title_embedding_120', Float32), ('title_embedding_121', Float32), ('title_embedding_122', Float32), ('title_embedding_123', Float32), ('title_embedding_124', Float32), ('title_embedding_125', Float32), ('title_embedding_126', Float32), ('title_embedding_127', Float32), ('title_embedding_128', Float32), ('title_embedding_129', Float32), ('title_embedding_130', Float32), ('title_embedding_131', Float32), ('title_embedding_132', Float32), ('title_embedding_133', Float32), ('title_embedding_134', Float32), ('title_embedding_135', Float32), ('title_embedding_136', Float32), ('title_embedding_137', Float32), ('title_embedding_138', Float32), ('title_embedding_139', Float32), ('title_embedding_140', Float32), ('title_embedding_141', Float32), ('title_embedding_142', Float32), ('title_embedding_143', Float32), ('title_embedding_144', Float32), ('title_embedding_145', Float32), ('title_embedding_146', Float32), ('title_embedding_147', Float32), ('title_embedding_148', Float32), ('title_embedding_149', Float32), ('title_embedding_150', Float32), ('title_embedding_151', Float32), ('title_embedding_152', Float32), ('title_embedding_153', Float32), ('title_embedding_154', Float32), ('title_embedding_155', Float32), ('title_embedding_156', Float32), ('title_embedding_157', Float32), ('title_embedding_158', Float32), ('title_embedding_159', Float32), ('title_embedding_160', Float32), ('title_embedding_161', Float32), ('title_embedding_162', Float32), ('title_embedding_163', Float32), ('title_embedding_164', Float32), ('title_embedding_165', Float32), ('title_embedding_166', Float32), ('title_embedding_167', Float32), ('title_embedding_168', Float32), ('title_embedding_169', Float32), ('title_embedding_170', Float32), ('title_embedding_171', Float32), ('title_embedding_172', Float32), ('title_embedding_173', Float32), ('title_embedding_174', Float32), ('title_embedding_175', Float32), ('title_embedding_176', Float32), ('title_embedding_177', Float32), ('title_embedding_178', Float32), ('title_embedding_179', Float32), ('title_embedding_180', Float32), ('title_embedding_181', Float32), ('title_embedding_182', Float32), ('title_embedding_183', Float32), ('title_embedding_184', Float32), ('title_embedding_185', Float32), ('title_embedding_186', Float32), ('title_embedding_187', Float32), ('title_embedding_188', Float32), ('title_embedding_189', Float32), ('title_embedding_190', Float32), ('title_embedding_191', Float32), ('title_embedding_192', Float32), ('title_embedding_193', Float32), ('title_embedding_194', Float32), ('title_embedding_195', Float32), ('title_embedding_196', Float32), ('title_embedding_197', Float32), ('title_embedding_198', Float32), ('title_embedding_199', Float32), ('title_embedding_200', Float32), ('title_embedding_201', Float32), ('title_embedding_202', Float32), ('title_embedding_203', Float32), ('title_embedding_204', Float32), ('title_embedding_205', Float32), ('title_embedding_206', Float32), ('title_embedding_207', Float32), ('title_embedding_208', Float32), ('title_embedding_209', Float32), ('title_embedding_210', Float32), ('title_embedding_211', Float32), ('title_embedding_212', Float32), ('title_embedding_213', Float32), ('title_embedding_214', Float32), ('title_embedding_215', Float32), ('title_embedding_216', Float32), ('title_embedding_217', Float32), ('title_embedding_218', Float32), ('title_embedding_219', Float32), ('title_embedding_220', Float32), ('title_embedding_221', Float32), ('title_embedding_222', Float32), ('title_embedding_223', Float32), ('title_embedding_224', Float32), ('title_embedding_225', Float32), ('title_embedding_226', Float32), ('title_embedding_227', Float32), ('title_embedding_228', Float32), ('title_embedding_229', Float32), ('title_embedding_230', Float32), ('title_embedding_231', Float32), ('title_embedding_232', Float32), ('title_embedding_233', Float32), ('title_embedding_234', Float32), ('title_embedding_235', Float32), ('title_embedding_236', Float32), ('title_embedding_237', Float32), ('title_embedding_238', Float32), ('title_embedding_239', Float32), ('title_embedding_240', Float32), ('title_embedding_241', Float32), ('title_embedding_242', Float32), ('title_embedding_243', Float32), ('title_embedding_244', Float32), ('title_embedding_245', Float32), ('title_embedding_246', Float32), ('title_embedding_247', Float32), ('title_embedding_248', Float32), ('title_embedding_249', Float32), ('title_embedding_250', Float32), ('title_embedding_251', Float32), ('title_embedding_252', Float32), ('title_embedding_253', Float32), ('title_embedding_254', Float32), ('title_embedding_255', Float32), ('title_embedding_256', Float32), ('title_embedding_257', Float32), ('title_embedding_258', Float32), ('title_embedding_259', Float32), ('title_embedding_260', Float32), ('title_embedding_261', Float32), ('title_embedding_262', Float32), ('title_embedding_263', Float32), ('title_embedding_264', Float32), ('title_embedding_265', Float32), ('title_embedding_266', Float32), ('title_embedding_267', Float32), ('title_embedding_268', Float32), ('title_embedding_269', Float32), ('title_embedding_270', Float32), ('title_embedding_271', Float32), ('title_embedding_272', Float32), ('title_embedding_273', Float32), ('title_embedding_274', Float32), ('title_embedding_275', Float32), ('title_embedding_276', Float32), ('title_embedding_277', Float32), ('title_embedding_278', Float32), ('title_embedding_279', Float32), ('title_embedding_280', Float32), ('title_embedding_281', Float32), ('title_embedding_282', Float32), ('title_embedding_283', Float32), ('title_embedding_284', Float32), ('title_embedding_285', Float32), ('title_embedding_286', Float32), ('title_embedding_287', Float32), ('title_embedding_288', Float32), ('title_embedding_289', Float32), ('title_embedding_290', Float32), ('title_embedding_291', Float32), ('title_embedding_292', Float32), ('title_embedding_293', Float32), ('title_embedding_294', Float32), ('title_embedding_295', Float32), ('title_embedding_296', Float32), ('title_embedding_297', Float32), ('title_embedding_298', Float32), ('title_embedding_299', Float32), ('title_embedding_300', Float32), ('title_embedding_301', Float32), ('title_embedding_302', Float32), ('title_embedding_303', Float32), ('title_embedding_304', Float32), ('title_embedding_305', Float32), ('title_embedding_306', Float32), ('title_embedding_307', Float32), ('title_embedding_308', Float32), ('title_embedding_309', Float32), ('title_embedding_310', Float32), ('title_embedding_311', Float32), ('title_embedding_312', Float32), ('title_embedding_313', Float32), ('title_embedding_314', Float32), ('title_embedding_315', Float32), ('title_embedding_316', Float32), ('title_embedding_317', Float32), ('title_embedding_318', Float32), ('title_embedding_319', Float32), ('title_embedding_320', Float32), ('title_embedding_321', Float32), ('title_embedding_322', Float32), ('title_embedding_323', Float32), ('title_embedding_324', Float32), ('title_embedding_325', Float32), ('title_embedding_326', Float32), ('title_embedding_327', Float32), ('title_embedding_328', Float32), ('title_embedding_329', Float32), ('title_embedding_330', Float32), ('title_embedding_331', Float32), ('title_embedding_332', Float32), ('title_embedding_333', Float32), ('title_embedding_334', Float32), ('title_embedding_335', Float32), ('title_embedding_336', Float32), ('title_embedding_337', Float32), ('title_embedding_338', Float32), ('title_embedding_339', Float32), ('title_embedding_340', Float32), ('title_embedding_341', Float32), ('title_embedding_342', Float32), ('title_embedding_343', Float32), ('title_embedding_344', Float32), ('title_embedding_345', Float32), ('title_embedding_346', Float32), ('title_embedding_347', Float32), ('title_embedding_348', Float32), ('title_embedding_349', Float32), ('title_embedding_350', Float32), ('title_embedding_351', Float32), ('title_embedding_352', Float32), ('title_embedding_353', Float32), ('title_embedding_354', Float32), ('title_embedding_355', Float32), ('title_embedding_356', Float32), ('title_embedding_357', Float32), ('title_embedding_358', Float32), ('title_embedding_359', Float32), ('title_embedding_360', Float32), ('title_embedding_361', Float32), ('title_embedding_362', Float32), ('title_embedding_363', Float32), ('title_embedding_364', Float32), ('title_embedding_365', Float32), ('title_embedding_366', Float32), ('title_embedding_367', Float32), ('title_embedding_368', Float32), ('title_embedding_369', Float32), ('title_embedding_370', Float32), ('title_embedding_371', Float32), ('title_embedding_372', Float32), ('title_embedding_373', Float32), ('title_embedding_374', Float32), ('title_embedding_375', Float32), ('title_embedding_376', Float32), ('title_embedding_377', Float32), ('title_embedding_378', Float32), ('title_embedding_379', Float32), ('title_embedding_380', Float32), ('title_embedding_381', Float32), ('title_embedding_382', Float32), ('title_embedding_383', Float32), ('transcript_embedding_0', Float32), ('transcript_embedding_1', Float32), ('transcript_embedding_2', Float32), ('transcript_embedding_3', Float32), ('transcript_embedding_4', Float32), ('transcript_embedding_5', Float32), ('transcript_embedding_6', Float32), ('transcript_embedding_7', Float32), ('transcript_embedding_8', Float32), ('transcript_embedding_9', Float32), ('transcript_embedding_10', Float32), ('transcript_embedding_11', Float32), ('transcript_embedding_12', Float32), ('transcript_embedding_13', Float32), ('transcript_embedding_14', Float32), ('transcript_embedding_15', Float32), ('transcript_embedding_16', Float32), ('transcript_embedding_17', Float32), ('transcript_embedding_18', Float32), ('transcript_embedding_19', Float32), ('transcript_embedding_20', Float32), ('transcript_embedding_21', Float32), ('transcript_embedding_22', Float32), ('transcript_embedding_23', Float32), ('transcript_embedding_24', Float32), ('transcript_embedding_25', Float32), ('transcript_embedding_26', Float32), ('transcript_embedding_27', Float32), ('transcript_embedding_28', Float32), ('transcript_embedding_29', Float32), ('transcript_embedding_30', Float32), ('transcript_embedding_31', Float32), ('transcript_embedding_32', Float32), ('transcript_embedding_33', Float32), ('transcript_embedding_34', Float32), ('transcript_embedding_35', Float32), ('transcript_embedding_36', Float32), ('transcript_embedding_37', Float32), ('transcript_embedding_38', Float32), ('transcript_embedding_39', Float32), ('transcript_embedding_40', Float32), ('transcript_embedding_41', Float32), ('transcript_embedding_42', Float32), ('transcript_embedding_43', Float32), ('transcript_embedding_44', Float32), ('transcript_embedding_45', Float32), ('transcript_embedding_46', Float32), ('transcript_embedding_47', Float32), ('transcript_embedding_48', Float32), ('transcript_embedding_49', Float32), ('transcript_embedding_50', Float32), ('transcript_embedding_51', Float32), ('transcript_embedding_52', Float32), ('transcript_embedding_53', Float32), ('transcript_embedding_54', Float32), ('transcript_embedding_55', Float32), ('transcript_embedding_56', Float32), ('transcript_embedding_57', Float32), ('transcript_embedding_58', Float32), ('transcript_embedding_59', Float32), ('transcript_embedding_60', Float32), ('transcript_embedding_61', Float32), ('transcript_embedding_62', Float32), ('transcript_embedding_63', Float32), ('transcript_embedding_64', Float32), ('transcript_embedding_65', Float32), ('transcript_embedding_66', Float32), ('transcript_embedding_67', Float32), ('transcript_embedding_68', Float32), ('transcript_embedding_69', Float32), ('transcript_embedding_70', Float32), ('transcript_embedding_71', Float32), ('transcript_embedding_72', Float32), ('transcript_embedding_73', Float32), ('transcript_embedding_74', Float32), ('transcript_embedding_75', Float32), ('transcript_embedding_76', Float32), ('transcript_embedding_77', Float32), ('transcript_embedding_78', Float32), ('transcript_embedding_79', Float32), ('transcript_embedding_80', Float32), ('transcript_embedding_81', Float32), ('transcript_embedding_82', Float32), ('transcript_embedding_83', Float32), ('transcript_embedding_84', Float32), ('transcript_embedding_85', Float32), ('transcript_embedding_86', Float32), ('transcript_embedding_87', Float32), ('transcript_embedding_88', Float32), ('transcript_embedding_89', Float32), ('transcript_embedding_90', Float32), ('transcript_embedding_91', Float32), ('transcript_embedding_92', Float32), ('transcript_embedding_93', Float32), ('transcript_embedding_94', Float32), ('transcript_embedding_95', Float32), ('transcript_embedding_96', Float32), ('transcript_embedding_97', Float32), ('transcript_embedding_98', Float32), ('transcript_embedding_99', Float32), ('transcript_embedding_100', Float32), ('transcript_embedding_101', Float32), ('transcript_embedding_102', Float32), ('transcript_embedding_103', Float32), ('transcript_embedding_104', Float32), ('transcript_embedding_105', Float32), ('transcript_embedding_106', Float32), ('transcript_embedding_107', Float32), ('transcript_embedding_108', Float32), ('transcript_embedding_109', Float32), ('transcript_embedding_110', Float32), ('transcript_embedding_111', Float32), ('transcript_embedding_112', Float32), ('transcript_embedding_113', Float32), ('transcript_embedding_114', Float32), ('transcript_embedding_115', Float32), ('transcript_embedding_116', Float32), ('transcript_embedding_117', Float32), ('transcript_embedding_118', Float32), ('transcript_embedding_119', Float32), ('transcript_embedding_120', Float32), ('transcript_embedding_121', Float32), ('transcript_embedding_122', Float32), ('transcript_embedding_123', Float32), ('transcript_embedding_124', Float32), ('transcript_embedding_125', Float32), ('transcript_embedding_126', Float32), ('transcript_embedding_127', Float32), ('transcript_embedding_128', Float32), ('transcript_embedding_129', Float32), ('transcript_embedding_130', Float32), ('transcript_embedding_131', Float32), ('transcript_embedding_132', Float32), ('transcript_embedding_133', Float32), ('transcript_embedding_134', Float32), ('transcript_embedding_135', Float32), ('transcript_embedding_136', Float32), ('transcript_embedding_137', Float32), ('transcript_embedding_138', Float32), ('transcript_embedding_139', Float32), ('transcript_embedding_140', Float32), ('transcript_embedding_141', Float32), ('transcript_embedding_142', Float32), ('transcript_embedding_143', Float32), ('transcript_embedding_144', Float32), ('transcript_embedding_145', Float32), ('transcript_embedding_146', Float32), ('transcript_embedding_147', Float32), ('transcript_embedding_148', Float32), ('transcript_embedding_149', Float32), ('transcript_embedding_150', Float32), ('transcript_embedding_151', Float32), ('transcript_embedding_152', Float32), ('transcript_embedding_153', Float32), ('transcript_embedding_154', Float32), ('transcript_embedding_155', Float32), ('transcript_embedding_156', Float32), ('transcript_embedding_157', Float32), ('transcript_embedding_158', Float32), ('transcript_embedding_159', Float32), ('transcript_embedding_160', Float32), ('transcript_embedding_161', Float32), ('transcript_embedding_162', Float32), ('transcript_embedding_163', Float32), ('transcript_embedding_164', Float32), ('transcript_embedding_165', Float32), ('transcript_embedding_166', Float32), ('transcript_embedding_167', Float32), ('transcript_embedding_168', Float32), ('transcript_embedding_169', Float32), ('transcript_embedding_170', Float32), ('transcript_embedding_171', Float32), ('transcript_embedding_172', Float32), ('transcript_embedding_173', Float32), ('transcript_embedding_174', Float32), ('transcript_embedding_175', Float32), ('transcript_embedding_176', Float32), ('transcript_embedding_177', Float32), ('transcript_embedding_178', Float32), ('transcript_embedding_179', Float32), ('transcript_embedding_180', Float32), ('transcript_embedding_181', Float32), ('transcript_embedding_182', Float32), ('transcript_embedding_183', Float32), ('transcript_embedding_184', Float32), ('transcript_embedding_185', Float32), ('transcript_embedding_186', Float32), ('transcript_embedding_187', Float32), ('transcript_embedding_188', Float32), ('transcript_embedding_189', Float32), ('transcript_embedding_190', Float32), ('transcript_embedding_191', Float32), ('transcript_embedding_192', Float32), ('transcript_embedding_193', Float32), ('transcript_embedding_194', Float32), ('transcript_embedding_195', Float32), ('transcript_embedding_196', Float32), ('transcript_embedding_197', Float32), ('transcript_embedding_198', Float32), ('transcript_embedding_199', Float32), ('transcript_embedding_200', Float32), ('transcript_embedding_201', Float32), ('transcript_embedding_202', Float32), ('transcript_embedding_203', Float32), ('transcript_embedding_204', Float32), ('transcript_embedding_205', Float32), ('transcript_embedding_206', Float32), ('transcript_embedding_207', Float32), ('transcript_embedding_208', Float32), ('transcript_embedding_209', Float32), ('transcript_embedding_210', Float32), ('transcript_embedding_211', Float32), ('transcript_embedding_212', Float32), ('transcript_embedding_213', Float32), ('transcript_embedding_214', Float32), ('transcript_embedding_215', Float32), ('transcript_embedding_216', Float32), ('transcript_embedding_217', Float32), ('transcript_embedding_218', Float32), ('transcript_embedding_219', Float32), ('transcript_embedding_220', Float32), ('transcript_embedding_221', Float32), ('transcript_embedding_222', Float32), ('transcript_embedding_223', Float32), ('transcript_embedding_224', Float32), ('transcript_embedding_225', Float32), ('transcript_embedding_226', Float32), ('transcript_embedding_227', Float32), ('transcript_embedding_228', Float32), ('transcript_embedding_229', Float32), ('transcript_embedding_230', Float32), ('transcript_embedding_231', Float32), ('transcript_embedding_232', Float32), ('transcript_embedding_233', Float32), ('transcript_embedding_234', Float32), ('transcript_embedding_235', Float32), ('transcript_embedding_236', Float32), ('transcript_embedding_237', Float32), ('transcript_embedding_238', Float32), ('transcript_embedding_239', Float32), ('transcript_embedding_240', Float32), ('transcript_embedding_241', Float32), ('transcript_embedding_242', Float32), ('transcript_embedding_243', Float32), ('transcript_embedding_244', Float32), ('transcript_embedding_245', Float32), ('transcript_embedding_246', Float32), ('transcript_embedding_247', Float32), ('transcript_embedding_248', Float32), ('transcript_embedding_249', Float32), ('transcript_embedding_250', Float32), ('transcript_embedding_251', Float32), ('transcript_embedding_252', Float32), ('transcript_embedding_253', Float32), ('transcript_embedding_254', Float32), ('transcript_embedding_255', Float32), ('transcript_embedding_256', Float32), ('transcript_embedding_257', Float32), ('transcript_embedding_258', Float32), ('transcript_embedding_259', Float32), ('transcript_embedding_260', Float32), ('transcript_embedding_261', Float32), ('transcript_embedding_262', Float32), ('transcript_embedding_263', Float32), ('transcript_embedding_264', Float32), ('transcript_embedding_265', Float32), ('transcript_embedding_266', Float32), ('transcript_embedding_267', Float32), ('transcript_embedding_268', Float32), ('transcript_embedding_269', Float32), ('transcript_embedding_270', Float32), ('transcript_embedding_271', Float32), ('transcript_embedding_272', Float32), ('transcript_embedding_273', Float32), ('transcript_embedding_274', Float32), ('transcript_embedding_275', Float32), ('transcript_embedding_276', Float32), ('transcript_embedding_277', Float32), ('transcript_embedding_278', Float32), ('transcript_embedding_279', Float32), ('transcript_embedding_280', Float32), ('transcript_embedding_281', Float32), ('transcript_embedding_282', Float32), ('transcript_embedding_283', Float32), ('transcript_embedding_284', Float32), ('transcript_embedding_285', Float32), ('transcript_embedding_286', Float32), ('transcript_embedding_287', Float32), ('transcript_embedding_288', Float32), ('transcript_embedding_289', Float32), ('transcript_embedding_290', Float32), ('transcript_embedding_291', Float32), ('transcript_embedding_292', Float32), ('transcript_embedding_293', Float32), ('transcript_embedding_294', Float32), ('transcript_embedding_295', Float32), ('transcript_embedding_296', Float32), ('transcript_embedding_297', Float32), ('transcript_embedding_298', Float32), ('transcript_embedding_299', Float32), ('transcript_embedding_300', Float32), ('transcript_embedding_301', Float32), ('transcript_embedding_302', Float32), ('transcript_embedding_303', Float32), ('transcript_embedding_304', Float32), ('transcript_embedding_305', Float32), ('transcript_embedding_306', Float32), ('transcript_embedding_307', Float32), ('transcript_embedding_308', Float32), ('transcript_embedding_309', Float32), ('transcript_embedding_310', Float32), ('transcript_embedding_311', Float32), ('transcript_embedding_312', Float32), ('transcript_embedding_313', Float32), ('transcript_embedding_314', Float32), ('transcript_embedding_315', Float32), ('transcript_embedding_316', Float32), ('transcript_embedding_317', Float32), ('transcript_embedding_318', Float32), ('transcript_embedding_319', Float32), ('transcript_embedding_320', Float32), ('transcript_embedding_321', Float32), ('transcript_embedding_322', Float32), ('transcript_embedding_323', Float32), ('transcript_embedding_324', Float32), ('transcript_embedding_325', Float32), ('transcript_embedding_326', Float32), ('transcript_embedding_327', Float32), ('transcript_embedding_328', Float32), ('transcript_embedding_329', Float32), ('transcript_embedding_330', Float32), ('transcript_embedding_331', Float32), ('transcript_embedding_332', Float32), ('transcript_embedding_333', Float32), ('transcript_embedding_334', Float32), ('transcript_embedding_335', Float32), ('transcript_embedding_336', Float32), ('transcript_embedding_337', Float32), ('transcript_embedding_338', Float32), ('transcript_embedding_339', Float32), ('transcript_embedding_340', Float32), ('transcript_embedding_341', Float32), ('transcript_embedding_342', Float32), ('transcript_embedding_343', Float32), ('transcript_embedding_344', Float32), ('transcript_embedding_345', Float32), ('transcript_embedding_346', Float32), ('transcript_embedding_347', Float32), ('transcript_embedding_348', Float32), ('transcript_embedding_349', Float32), ('transcript_embedding_350', Float32), ('transcript_embedding_351', Float32), ('transcript_embedding_352', Float32), ('transcript_embedding_353', Float32), ('transcript_embedding_354', Float32), ('transcript_embedding_355', Float32), ('transcript_embedding_356', Float32), ('transcript_embedding_357', Float32), ('transcript_embedding_358', Float32), ('transcript_embedding_359', Float32), ('transcript_embedding_360', Float32), ('transcript_embedding_361', Float32), ('transcript_embedding_362', Float32), ('transcript_embedding_363', Float32), ('transcript_embedding_364', Float32), ('transcript_embedding_365', Float32), ('transcript_embedding_366', Float32), ('transcript_embedding_367', Float32), ('transcript_embedding_368', Float32), ('transcript_embedding_369', Float32), ('transcript_embedding_370', Float32), ('transcript_embedding_371', Float32), ('transcript_embedding_372', Float32), ('transcript_embedding_373', Float32), ('transcript_embedding_374', Float32), ('transcript_embedding_375', Float32), ('transcript_embedding_376', Float32), ('transcript_embedding_377', Float32), ('transcript_embedding_378', Float32), ('transcript_embedding_379', Float32), ('transcript_embedding_380', Float32), ('transcript_embedding_381', Float32), ('transcript_embedding_382', Float32), ('transcript_embedding_383', Float32)])\n",
      "\n",
      "--- Informazioni sugli Embedding ---\n",
      "Trovate 384 colonne di embedding per 'title' (es. da 'title_embedding_0' a 'title_embedding_383').\n",
      "Trovate 384 colonne di embedding per 'transcript' (es. da 'transcript_embedding_0' a 'transcript_embedding_383').\n",
      "\n",
      "--- Dimensioni totali del DataFrame finale ---\n",
      "Numero di righe (video): 139\n",
      "Numero di colonne: 772\n"
     ]
    }
   ],
   "source": [
    "final_output_path = os.path.join(DATA_DIR, 'video-index.parquet')\n",
    "\n",
    "if os.path.exists(final_output_path):\n",
    "    print(f\"Ispezione del file di output finale: '{final_output_path}'\")\n",
    "    df_final = pl.read_parquet(final_output_path)\n",
    "\n",
    "    if not df_final.is_empty():\n",
    "        print(\"\\n--- Prime 5 righe del DataFrame finale ---\")\n",
    "        # Selezioniamo colonne rappresentative, inclusa un'anteprima della trascrizione\n",
    "        cols_to_show_head = ['video_id', 'datetime', 'title']\n",
    "        if 'transcript' in df_final.columns:\n",
    "            cols_to_show_head.append('transcript')\n",
    "\n",
    "        # Assicuriamoci che le colonne esistano prima di selezionarle\n",
    "        existing_cols_for_head = [col for col in cols_to_show_head if col in df_final.columns]\n",
    "\n",
    "        if existing_cols_for_head:\n",
    "            if 'transcript' in existing_cols_for_head:\n",
    "                # Mostra solo i primi 100 caratteri della trascrizione per leggibilità\n",
    "                print(df_final.select(existing_cols_for_head).with_columns(pl.col('transcript').str.slice(0, 100).alias('transcript_preview')).head())\n",
    "            else:\n",
    "                print(df_final.select(existing_cols_for_head).head())\n",
    "        else:\n",
    "            print(\"Nessuna delle colonne di base ('video_id', 'datetime', 'title', 'transcript') trovata per l'anteprima.\")\n",
    "            print(\"Mostro tutte le colonne disponibili (prime 5 righe):\")\n",
    "            print(df_final.head())\n",
    "\n",
    "        print(\"\\n--- Schema del DataFrame finale (tipi di dati) ---\")\n",
    "        print(df_final.schema)\n",
    "        # Verifica che 'datetime' sia di tipo Datetime e che ci siano colonne di embedding (float).\n",
    "\n",
    "        # Controlla la presenza e il numero di colonne di embedding\n",
    "        title_embedding_cols = [col for col in df_final.columns if 'title_embedding' in col]\n",
    "        transcript_embedding_cols = [col for col in df_final.columns if 'transcript_embedding' in col]\n",
    "\n",
    "        print(\"\\n--- Informazioni sugli Embedding ---\")\n",
    "        if title_embedding_cols:\n",
    "            print(f\"Trovate {len(title_embedding_cols)} colonne di embedding per 'title' (es. da '{title_embedding_cols[0]}' a '{title_embedding_cols[-1]}').\")\n",
    "        else:\n",
    "            print(\"Nessuna colonna di embedding per 'title' trovata. Controllare il log del Passo 4.\")\n",
    "\n",
    "        if transcript_embedding_cols:\n",
    "            print(f\"Trovate {len(transcript_embedding_cols)} colonne di embedding per 'transcript' (es. da '{transcript_embedding_cols[0]}' a '{transcript_embedding_cols[-1]}').\")\n",
    "        else:\n",
    "            print(\"Nessuna colonna di embedding per 'transcript' trovata. Controllare il log del Passo 4.\")\n",
    "\n",
    "        print(\"\\n--- Dimensioni totali del DataFrame finale ---\")\n",
    "        print(f\"Numero di righe (video): {df_final.shape[0]}\")\n",
    "        print(f\"Numero di colonne: {df_final.shape[1]}\")\n",
    "    else:\n",
    "        print(\"Il file di output finale è vuoto. Controllare i log dei passaggi precedenti per eventuali errori o dati segnaposto.\")\n",
    "else:\n",
    "    print(f\"ERRORE: File di output finale '{final_output_path}' non trovato. La pipeline potrebbe non essere stata completata con successo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ab5496",
   "metadata": {
    "id": "74ab5496"
   },
   "source": [
    "## 7. Conclusioni e Prossimi Passi\n",
    "\n",
    "Congratulazioni! Hai costruito ed eseguito con successo una pipeline completa per l'elaborazione di dati da video di YouTube. Abbiamo coperto i seguenti passaggi chiave:\n",
    "\n",
    "1.  **Estrazione dei Metadati**: Recupero di ID video, titoli e date di pubblicazione tramite l'API di YouTube.\n",
    "2.  **Estrazione delle Trascrizioni**: Download delle trascrizioni testuali dei video.\n",
    "3.  **Validazione e Trasformazione dei Dati**: Ispezione dei dati per problemi di qualità e successiva applicazione di pulizia (caratteri speciali) e standardizzazione (tipi di dato).\n",
    "4.  **Generazione di Embedding**: Creazione di rappresentazioni vettoriali semantiche per titoli e trascrizioni.\n",
    "5.  **Salvataggio**: Memorizzazione efficiente dei dati intermedi e finali in formato Parquet.\n",
    "\n",
    "**Prossimi Passi Potenziali:**\n",
    "\n",
    "* **Analisi Esplorativa Approfondita**: Utilizzare il `video-index.parquet` finale per analisi più complesse (es. topic modeling sulle trascrizioni, analisi temporale delle pubblicazioni, correlazione tra titoli e popolarità – se avessimo dati di view count).\n",
    "* **Costruzione di un Motore di Ricerca Semantica**: Sfruttare gli embedding generati per costruire un sistema che permetta di cercare video basandosi sul significato delle query e non solo sulle parole chiave.\n",
    "* **Miglioramento della Pipeline**:\n",
    "    * Aggiungere la gestione di errori più robusta e logging dettagliato.\n",
    "    * Integrare il recupero di ulteriori metadati (es. conteggio visualizzazioni, like, commenti) se disponibili e utili.\n",
    "    * Ottimizzare le performance per dataset molto più grandi.\n",
    "    * Parametrizzare ulteriormente la pipeline (es. ID del canale, modello di embedding) per renderla più flessibile.\n",
    "* **Deployment e Automazione Avanzata**: Oltre a GitHub Actions, esplorare strumenti come Apache Airflow o Kubeflow Pipelines per orchestrare pipeline di dati complesse in ambienti di produzione.\n",
    "* **Versionamento dei Dati**: Utilizzare strumenti come DVC (Data Version Control) per tracciare le versioni dei dataset e dei modelli, garantendo la riproducibilità.\n",
    "\n",
    "Questo notebook fornisce una solida base per comprendere e implementare pipeline di dati end-to-end. Le competenze acquisite sono trasferibili a molti altri domini e tipi di dati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b80e7",
   "metadata": {
    "id": "642b80e7"
   },
   "source": [
    "## 8. Automazione della Pipeline con GitHub Actions\n",
    "\n",
    "Finora abbiamo eseguito la pipeline manualmente all'interno di questo Jupyter Notebook. Per un utilizzo più robusto e in scenari reali (es. aggiornare periodicamente i dati, deployment), è fondamentale automatizzare l'esecuzione della pipeline. GitHub Actions è uno strumento potente e integrato in GitHub che ci permette di farlo.\n",
    "\n",
    "### 8.1 Cos'è GitHub Actions?\n",
    "GitHub Actions è una piattaforma di Integrazione Continua e Continuous Delivery (CI/CD) che ti permette di automatizzare il tuo workflow di sviluppo software, inclusa la compilazione, il testing e il deployment del codice, direttamente da GitHub. Puoi creare workflow personalizzati che vengono eseguiti in risposta a eventi specifici (es. un push sul repository, la creazione di una Pull Request, una schedulazione temporale).\n",
    "\n",
    "### 8.2 Perché Automatizzare questa Pipeline Dati?\n",
    "Automatizzare la nostra pipeline per i dati di YouTube offre diversi vantaggi:\n",
    "* **Aggiornamenti Automatici:** Può essere schedulata per recuperare nuovi video e trascrizioni automaticamente (es. ogni giorno, ogni settimana).\n",
    "* **Riproducibilità:** Assicura che la pipeline venga eseguita sempre nello stesso ambiente configurato, riducendo errori dovuti a configurazioni locali diverse.\n",
    "* **Tracciabilità:** Ogni esecuzione viene loggata, facilitando il debug e il monitoraggio.\n",
    "* **Collaborazione:** Facilita la collaborazione, poiché il processo di aggiornamento dei dati è standardizzato e non dipende da un singolo sviluppatore.\n",
    "\n",
    "### 8.3 Come Configurare una GitHub Action per questa Pipeline\n",
    "\n",
    "Per automatizzare la nostra pipeline, idealmente utilizzeremmo gli script Python (`data_pipeline.py` e `functions.py` dalla cartella `src/` come descritto nella Sezione 1.1) piuttosto che questo notebook interattivo. Lo script `data_pipeline.py` è già progettato per essere eseguito da riga di comando.\n",
    "\n",
    "**Struttura dei file per GitHub Actions (esempio):**\n",
    "Supponiamo che il tuo repository GitHub abbia questa struttura:\n",
    "```\n",
    "youtube_data_pipeline_project/\n",
    "|-- src/\n",
    "|   |-- functions.py\n",
    "|   |-- data_pipeline.py\n",
    "|-- data/                     # Potrebbe essere vuota o contenere dati iniziali\n",
    "|-- requirements.txt\n",
    "|-- .github/workflows/\n",
    "|   |-- youtube_data_pipeline.yml\n",
    "```\n",
    "\n",
    "**Passaggi principali per la configurazione:**\n",
    "\n",
    "1.  **Prepara gli Script Python e le Dipendenze:**\n",
    "    * Assicurati che `src/data_pipeline.py` e `src/functions.py` siano nel tuo repository. Lo script `data_pipeline.py` dovrebbe orchestrare la chiamata delle funzioni da `functions.py` per eseguire l'intera pipeline, leggendo e scrivendo file nella cartella `data/` (relativa alla posizione dello script).\n",
    "    * Verifica che un file `requirements.txt` (contenente `polars`, `youtube_transcript_api`, `sentence-transformers`, `requests`, `accelerate`) sia presente nella root del progetto o in una posizione accessibile dal workflow (es. `src/requirements.txt`).\n",
    "\n",
    "2.  **Crea un File di Workflow YAML:**\n",
    "    Crea una cartella `.github/workflows/` nella root del tuo repository (se non esiste già). All'interno di questa cartella, crea un file YAML, ad esempio `youtube_data_pipeline.yml`.\n",
    "\n",
    "3.  **Definisci il Workflow nel File YAML:**\n",
    "    Ecco un esempio di come potrebbe apparire il contenuto del file `youtube_data_pipeline.yml`:\n",
    "\n",
    "    ```yaml\n",
    "    name: YouTube Data Pipeline - Aggiornamento Automatico\n",
    "\n",
    "    on:\n",
    "      schedule:\n",
    "        # Esegue la pipeline ogni giorno alle 02:00 UTC (configurabile)\n",
    "        - cron: '0 2 * * *'\n",
    "      workflow_dispatch: # Permette l'avvio manuale dalla UI di GitHub Actions\n",
    "\n",
    "    jobs:\n",
    "      run-youtube-data-pipeline:\n",
    "        runs-on: ubuntu-latest # Specifica il sistema operativo del runner\n",
    "        \n",
    "        defaults:\n",
    "          run:\n",
    "            # Imposta la directory di lavoro per gli script Python\n",
    "            # Assumendo che data_pipeline.py e functions.py siano in src/\n",
    "            # e requirements.txt nella root del progetto.\n",
    "            working-directory: ./src\n",
    "\n",
    "        steps:\n",
    "          - name: Checkout repository\n",
    "            # Azione per scaricare il codice del repository sul runner\n",
    "            uses: actions/checkout@v4\n",
    "\n",
    "          - name: Set up Python\n",
    "            # Azione per configurare l'ambiente Python\n",
    "            uses: actions/setup-python@v5\n",
    "            with:\n",
    "              python-version: '3.10' # Specifica la versione di Python\n",
    "\n",
    "          - name: Install dependencies\n",
    "            run: |\n",
    "              python -m pip install --upgrade pip\n",
    "              # Installa le dipendenze dal requirements.txt nella root del progetto\n",
    "              pip install -r ../requirements.txt\n",
    "            # Nota: il path di requirements.txt è relativo a working-directory (./src)\n",
    "            # Se requirements.txt fosse in ./src, sarebbe pip install -r requirements.txt\n",
    "\n",
    "          - name: Run YouTube Data Pipeline Script\n",
    "            env:\n",
    "              # Usa un secret di GitHub per la chiave API. MAI hardcodarla!\n",
    "              YT_API_KEY: ${{ secrets.YT_API_KEY }}\n",
    "            # Esegue lo script principale della pipeline. Lo script si aspetta di trovare/creare una cartella 'data'\n",
    "            # relativa alla sua posizione (quindi src/data/ se DATA_DIR non è un path assoluto).\n",
    "            # Assicurati che data_pipeline.py gestisca correttamente i path per la cartella 'data'.\n",
    "            # Una soluzione comune è creare la cartella 'data' relativa allo script o usare path assoluti gestiti da config.\n",
    "            # Per questo esempio, assumiamo che gli script creino/usino una cartella 'data' all'interno di 'src' o\n",
    "            # che i path in functions.py siano relativi a 'src/'.\n",
    "            # Idealmente, functions.py e data_pipeline.py dovrebbero usare path relativi\n",
    "            # che puntino a una cartella 'data' nella root del progetto, es. ../data/\n",
    "            # Modifica: Creiamo la cartella data nella root prima di eseguire lo script\n",
    "          - name: Create data directory in project root if not exists\n",
    "            run: mkdir -p ../data\n",
    "            working-directory: . # Temporaneamente cambia working-directory per creare la cartella data nella root\n",
    "            \n",
    "          - name: Run YouTube Data Pipeline Script (con data dir nella root)\n",
    "            env:\n",
    "              YT_API_KEY: ${{ secrets.YT_API_KEY }}\n",
    "            # Assumendo che gli script in src/ siano stati modificati per usare '../data' come DATA_DIR\n",
    "            run: python data_pipeline.py\n",
    "            working-directory: ./src # Ritorna alla working-directory per lo script\n",
    "\n",
    "          - name: Commit and push data changes (Opzionale)\n",
    "            # Questo passo è opzionale. Gestisce il commit dei file Parquet generati.\n",
    "            # Per dataset grandi, considera Git LFS o storage esterno (S3, GCS).\n",
    "            run: |\n",
    "              git config --global user.name 'GitHub Action Bot'\n",
    "              git config --global user.email 'action-bot@github.com'\n",
    "              # Controlla se ci sono modifiche nella cartella '../data/' (relativa a ./src)\n",
    "              # Attenzione: il path qui deve essere corretto rispetto alla working-directory corrente (./src)\n",
    "              if ! git diff --quiet ../data/; then\n",
    "                git add ../data/\n",
    "                git commit -m \"Aggiornamento automatico dati video YouTube ($(date +'%Y-%m-%d %H:%M:%S'))\"\n",
    "                git push\n",
    "              else\n",
    "                echo \"Nessuna modifica ai dati da committare.\"\n",
    "              fi\n",
    "            working-directory: ./src # Assicura che i comandi git siano eseguiti da ./src\n",
    "            continue-on-error: true # Continua anche se il push fallisce (es. per fork senza permessi)\n",
    "    ```\n",
    "\n",
    "    **Spiegazione dettagliata del file YAML:**\n",
    "    * `name`: Nome del workflow (es. `YouTube Data Pipeline - Aggiornamento Automatico`).\n",
    "    * `on`: Definisce gli eventi che attivano il workflow.\n",
    "        * `schedule - cron: '0 2 * * *'`: Esegue il workflow a intervalli regolari (qui, ogni giorno alle 02:00 UTC).\n",
    "        * `workflow_dispatch`: Permette di avviare il workflow manualmente dalla tab \"Actions\" del repository GitHub.\n",
    "    * `jobs`: Contiene uno o più job (attività) da eseguire.\n",
    "        * `run-youtube-data-pipeline`: Nome del nostro job.\n",
    "        * `runs-on: ubuntu-latest`: Specifica il tipo di runner (macchina virtuale) su cui eseguire il job.\n",
    "        * `defaults.run.working-directory: ./src`: Imposta la directory di lavoro predefinita per i comandi `run` all'interno del job a `./src`. Questo è cruciale se `data_pipeline.py` si aspetta di essere eseguito da `src/` e i path ai dati (es. `../data/`) sono relativi a quella posizione.\n",
    "        * `steps`:\n",
    "            * `actions/checkout@v4`: Azione standard per fare il checkout (scaricare) il codice del tuo repository sul runner.\n",
    "            * `actions/setup-python@v5`: Azione per configurare l'ambiente Python alla versione specificata (`3.10`).\n",
    "            * `Install dependencies`: Esegue i comandi per installare le librerie Python. Il path `../requirements.txt` è relativo alla `working-directory` (`./src`), quindi punta alla root del progetto.\n",
    "            * `Create data directory...`: Questo step è stato aggiunto per creare la cartella `data` nella root del progetto, assumendo che gli script in `src/` siano stati adattati per salvare i dati lì (es. usando `os.path.join('..', 'data', 'nomefile.parquet')`).\n",
    "            * `Run YouTube Data Pipeline Script...`: Esegue lo script principale.\n",
    "                * `env.YT_API_KEY: ${{ secrets.YT_API_KEY }}`: **Fondamentale per la sicurezza.** La chiave API di YouTube non deve essere scritta nel codice o nel workflow. Va memorizzata come un \"secret\" nelle impostazioni del tuo repository GitHub (Settings -> Secrets and variables -> Actions -> New repository secret). Il workflow la leggerà da lì e la imposterà come variabile d'ambiente per lo script Python.\n",
    "                * `run: python data_pipeline.py`: Esegue lo script. È importante che `data_pipeline.py` (e `functions.py`) sappiano dove leggere/scrivere i file di dati (es. in una cartella `../data/` relativa a `src/` se `DATA_DIR` è definito come `os.path.join('..', 'data')` negli script).\n",
    "            * `Commit and push data changes (Opzionale)`: Questo passo mostra come fare il commit dei file di dati generati (es. i file Parquet nella cartella `data/` nella root del progetto) e pusharli al repository. **Attenzione ai percorsi qui (`../data/`) relativi alla `working-directory` (`./src`).**\n",
    "\n",
    "4.  **Aggiungi la Chiave API come Secret su GitHub:**\n",
    "    * Vai al tuo repository su GitHub.\n",
    "    * Settings -> Secrets and variables -> Actions.\n",
    "    * Clicca su \"New repository secret\".\n",
    "    * Nomina il secret `YT_API_KEY` e incolla la tua chiave API come valore.\n",
    "\n",
    "5.  **Adatta gli Script Python per i Path dei Dati:**\n",
    "    È cruciale che i tuoi script Python (`functions.py` e `data_pipeline.py`) gestiscano correttamente i percorsi per la cartella `data`. Se il workflow esegue gli script da `src/`, e vuoi che i dati siano salvati in `youtube_data_pipeline_project/data/`, allora negli script dovrai usare percorsi relativi come `os.path.join('..', 'data', 'nomefile.parquet')` per `DATA_DIR` o per i singoli path dei file.\n",
    "    Ad esempio, in `functions.py` o all'inizio di `data_pipeline.py`, potresti definire `DATA_DIR = os.path.join(os.path.dirname(__file__), '..', 'data')` per far sì che punti alla cartella `data` nella root del progetto, assumendo che `functions.py` sia in `src`.\n",
    "\n",
    "6.  **Commit e Push del Workflow:**\n",
    "    Fai il commit del file `.github/workflows/youtube_data_pipeline.yml`, degli script Python aggiornati (se necessario per i path) e del file `requirements.txt`. Pusha tutto sul tuo repository GitHub. GitHub Actions rileverà automaticamente il nuovo workflow.\n",
    "\n",
    "### 8.4 Considerazioni Aggiuntive sull'Automazione\n",
    "* **Gestione degli Output dei Dati**: Se i file Parquet diventano molto grandi, fare il commit diretto su Git non è ideale. Considera:\n",
    "    * **Git LFS (Large File Storage)**: Per versionare file grandi con Git.\n",
    "    * **Artefatti del Workflow**: Salva i dati come artefatti dell'esecuzione di GitHub Actions.\n",
    "    * **Storage Cloud Esterno**: Carica gli output su servizi come Amazon S3, Google Cloud Storage, Azure Blob Storage.\n",
    "* **Logging e Notifiche**: GitHub Actions fornisce log dettagliati per ogni esecuzione. Puoi configurare notifiche (es. email, Slack) in caso di fallimento del workflow.\n",
    "* **Test del Workflow**: Prima di affidarti completamente alla schedulazione, testa il workflow triggerandolo manualmente (`workflow_dispatch`) o pushando su un branch di sviluppo dedicato.\n",
    "* **Costi delle API e Quote**: Le esecuzioni automatiche frequenti dell'API di YouTube potrebbero consumare la tua quota API gratuita o generare costi. Monitora l'utilizzo e adatta la frequenza di schedulazione di conseguenza.\n",
    "\n",
    "Automatizzare la tua pipeline dati con GitHub Actions è un passo importante verso la creazione di sistemi di data science più robusti, affidabili e manutenibili."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "17b675bbfd9d49c28b29b20c474e9d66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33e9ca2fc0bf4f408035dc8df0c5a8f9",
      "placeholder": "​",
      "style": "IPY_MODEL_40a9581e887a4b18bbc04068315e3409",
      "value": " 5/5 [00:01&lt;00:00,  3.49it/s]"
     }
    },
    "33e9ca2fc0bf4f408035dc8df0c5a8f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3659262f9ecc4d829698fef4e2616050": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38455d27830f44aba12460b2ea062413": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f2db9b9d6af4e36a94244139f37fb03",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cb5a1d2dca9b468da8c4a4cf11e35521",
      "value": 5
     }
    },
    "40a9581e887a4b18bbc04068315e3409": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "463290d01f1f46c3bdd6c6c0b2465835": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4bc4f5aadbad45d08b8a0e6906599bdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f9c3e28e9a0456d8a2bb0107481f2bf",
       "IPY_MODEL_88b5b010c28c47f98f791393197f2f3c",
       "IPY_MODEL_7ba77796f73143789550b810ef04ad96"
      ],
      "layout": "IPY_MODEL_f6e0ef0842fc49cd9242f033f02e1c16"
     }
    },
    "5c2c6ed73c454b41bf7d3dd922309dd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d97f981f0a2a4fd1925f6a969c2218ae",
      "placeholder": "​",
      "style": "IPY_MODEL_915b4e7c0cdc4d24a4b47db085933fea",
      "value": "Batches: 100%"
     }
    },
    "671b9a267413483c8e4979d57bdbca14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f2db9b9d6af4e36a94244139f37fb03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f4d3bd95408460fb00774dc0c034efe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ba77796f73143789550b810ef04ad96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_671b9a267413483c8e4979d57bdbca14",
      "placeholder": "​",
      "style": "IPY_MODEL_463290d01f1f46c3bdd6c6c0b2465835",
      "value": " 5/5 [00:00&lt;00:00, 13.42it/s]"
     }
    },
    "7c50c76efa314a70972b7f6dce86aaab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5c2c6ed73c454b41bf7d3dd922309dd2",
       "IPY_MODEL_38455d27830f44aba12460b2ea062413",
       "IPY_MODEL_17b675bbfd9d49c28b29b20c474e9d66"
      ],
      "layout": "IPY_MODEL_6f4d3bd95408460fb00774dc0c034efe"
     }
    },
    "88b5b010c28c47f98f791393197f2f3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3659262f9ecc4d829698fef4e2616050",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db118d2048b844eab6f786050a6828cc",
      "value": 5
     }
    },
    "915b4e7c0cdc4d24a4b47db085933fea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f9c3e28e9a0456d8a2bb0107481f2bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f12497ac20f247e0a570b70cf2db5d65",
      "placeholder": "​",
      "style": "IPY_MODEL_f7fc22cfd0744b2e802828e5978dedb6",
      "value": "Batches: 100%"
     }
    },
    "cb5a1d2dca9b468da8c4a4cf11e35521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d97f981f0a2a4fd1925f6a969c2218ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db118d2048b844eab6f786050a6828cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f12497ac20f247e0a570b70cf2db5d65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6e0ef0842fc49cd9242f033f02e1c16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7fc22cfd0744b2e802828e5978dedb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
